{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn, concat, slice, stack, tensor, tidy, unstack, util, io, Tensor, add, addN, mod, mul, div, floorDiv, sub, minimum, maximum, pow, squaredDifference, abs, acos, acosh, asin, asinh, atan, atan2, atanh, ceil, cos, cosh, elu, erf, exp, expm1, floor, log, log1p, neg, reciprocal, relu, round, selu, sigmoid, sin, sign, sinh, softplus, sqrt, square, tanh, tan, clipByValue, scalar, prod, leakyRelu, conv1d, conv2d, conv2dTranspose, depthwiseConv2d, avgPool, maxPool, fill, linspace, oneHot, ones, onesLike, randomUniform, range, truncatedNormal, zeros, zerosLike, image, whereAsync, setdiff1dAsync, topk, tensor1d, equal, notEqual, greater, greaterEqual, less, lessEqual, logicalAnd, logicalNot, logicalOr, where, matMul, transpose, batchNorm, localResponseNormalization, softmax, logSoftmax, sparseToDense, max, mean, min, sum, all, any, argMax, argMin, gather, reverse, stridedSlice, tile, split, scatterND, gatherND, fft, ifft, rfft, irfft, cast, expandDims, squeeze, reshape, pad, spaceToBatchND, batchToSpaceND, depthToSpace } from \"@tensorflow/tfjs-core\";\n\nvar __assign = Object.assign || function (e) {\n  for (var t, a = 1, r = arguments.length; a < r; a++) {\n    for (var n in t = arguments[a]) {\n      Object.prototype.hasOwnProperty.call(t, n) && (e[n] = t[n]);\n    }\n  }\n\n  return e;\n};\n\nfunction __awaiter(e, t, a, r) {\n  return new (a || (a = Promise))(function (n, o) {\n    function s(e) {\n      try {\n        p(r.next(e));\n      } catch (e) {\n        o(e);\n      }\n    }\n\n    function i(e) {\n      try {\n        p(r.throw(e));\n      } catch (e) {\n        o(e);\n      }\n    }\n\n    function p(e) {\n      e.done ? n(e.value) : new a(function (t) {\n        t(e.value);\n      }).then(s, i);\n    }\n\n    p((r = r.apply(e, t || [])).next());\n  });\n}\n\nfunction __generator(e, t) {\n  var a,\n      r,\n      n,\n      o,\n      s = {\n    label: 0,\n    sent: function sent() {\n      if (1 & n[0]) throw n[1];\n      return n[1];\n    },\n    trys: [],\n    ops: []\n  };\n  return o = {\n    next: i(0),\n    throw: i(1),\n    return: i(2)\n  }, \"function\" == typeof Symbol && (o[Symbol.iterator] = function () {\n    return this;\n  }), o;\n\n  function i(o) {\n    return function (i) {\n      return function (o) {\n        if (a) throw new TypeError(\"Generator is already executing.\");\n\n        for (; s;) {\n          try {\n            if (a = 1, r && (n = r[2 & o[0] ? \"return\" : o[0] ? \"throw\" : \"next\"]) && !(n = n.call(r, o[1])).done) return n;\n\n            switch (r = 0, n && (o = [0, n.value]), o[0]) {\n              case 0:\n              case 1:\n                n = o;\n                break;\n\n              case 4:\n                return s.label++, {\n                  value: o[1],\n                  done: !1\n                };\n\n              case 5:\n                s.label++, r = o[1], o = [0];\n                continue;\n\n              case 7:\n                o = s.ops.pop(), s.trys.pop();\n                continue;\n\n              default:\n                if (!(n = (n = s.trys).length > 0 && n[n.length - 1]) && (6 === o[0] || 2 === o[0])) {\n                  s = 0;\n                  continue;\n                }\n\n                if (3 === o[0] && (!n || o[1] > n[0] && o[1] < n[3])) {\n                  s.label = o[1];\n                  break;\n                }\n\n                if (6 === o[0] && s.label < n[1]) {\n                  s.label = n[1], n = o;\n                  break;\n                }\n\n                if (n && s.label < n[2]) {\n                  s.label = n[2], s.ops.push(o);\n                  break;\n                }\n\n                n[2] && s.ops.pop(), s.trys.pop();\n                continue;\n            }\n\n            o = t.call(e, s);\n          } catch (e) {\n            o = [6, e], r = 0;\n          } finally {\n            a = n = 0;\n          }\n        }\n\n        if (5 & o[0]) throw o[1];\n        return {\n          value: o[0] ? o[1] : void 0,\n          done: !0\n        };\n      }([o, i]);\n    };\n  }\n}\n\nvar commonjsGlobal = \"undefined\" != typeof window ? window : \"undefined\" != typeof global ? global : \"undefined\" != typeof self ? self : {};\n\nfunction createCommonjsModule(e, t) {\n  return e(t = {\n    exports: {}\n  }, t.exports), t.exports;\n}\n\nvar aspromise = asPromise;\n\nfunction asPromise(e, t) {\n  for (var a = new Array(arguments.length - 1), r = 0, n = 2, o = !0; n < arguments.length;) {\n    a[r++] = arguments[n++];\n  }\n\n  return new Promise(function (n, s) {\n    a[r] = function (e) {\n      if (o) if (o = !1, e) s(e);else {\n        for (var t = new Array(arguments.length - 1), a = 0; a < t.length;) {\n          t[a++] = arguments[a];\n        }\n\n        n.apply(null, t);\n      }\n    };\n\n    try {\n      e.apply(t || null, a);\n    } catch (e) {\n      o && (o = !1, s(e));\n    }\n  });\n}\n\nvar base64_1 = createCommonjsModule(function (e, t) {\n  var a = t;\n\n  a.length = function (e) {\n    var t = e.length;\n    if (!t) return 0;\n\n    for (var a = 0; --t % 4 > 1 && \"=\" === e.charAt(t);) {\n      ++a;\n    }\n\n    return Math.ceil(3 * e.length) / 4 - a;\n  };\n\n  for (var r = new Array(64), n = new Array(123), o = 0; o < 64;) {\n    n[r[o] = o < 26 ? o + 65 : o < 52 ? o + 71 : o < 62 ? o - 4 : o - 59 | 43] = o++;\n  }\n\n  a.encode = function (e, t, a) {\n    for (var n, o = null, s = [], i = 0, p = 0; t < a;) {\n      var u = e[t++];\n\n      switch (p) {\n        case 0:\n          s[i++] = r[u >> 2], n = (3 & u) << 4, p = 1;\n          break;\n\n        case 1:\n          s[i++] = r[n | u >> 4], n = (15 & u) << 2, p = 2;\n          break;\n\n        case 2:\n          s[i++] = r[n | u >> 6], s[i++] = r[63 & u], p = 0;\n      }\n\n      i > 8191 && ((o || (o = [])).push(String.fromCharCode.apply(String, s)), i = 0);\n    }\n\n    return p && (s[i++] = r[n], s[i++] = 61, 1 === p && (s[i++] = 61)), o ? (i && o.push(String.fromCharCode.apply(String, s.slice(0, i))), o.join(\"\")) : String.fromCharCode.apply(String, s.slice(0, i));\n  };\n\n  a.decode = function (e, t, a) {\n    for (var r, o = a, s = 0, i = 0; i < e.length;) {\n      var p = e.charCodeAt(i++);\n      if (61 === p && s > 1) break;\n      if (void 0 === (p = n[p])) throw Error(\"invalid encoding\");\n\n      switch (s) {\n        case 0:\n          r = p, s = 1;\n          break;\n\n        case 1:\n          t[a++] = r << 2 | (48 & p) >> 4, r = p, s = 2;\n          break;\n\n        case 2:\n          t[a++] = (15 & r) << 4 | (60 & p) >> 2, r = p, s = 3;\n          break;\n\n        case 3:\n          t[a++] = (3 & r) << 6 | p, s = 0;\n      }\n    }\n\n    if (1 === s) throw Error(\"invalid encoding\");\n    return a - o;\n  }, a.test = function (e) {\n    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(e);\n  };\n}),\n    eventemitter = EventEmitter;\n\nfunction EventEmitter() {\n  this._listeners = {};\n}\n\nEventEmitter.prototype.on = function (e, t, a) {\n  return (this._listeners[e] || (this._listeners[e] = [])).push({\n    fn: t,\n    ctx: a || this\n  }), this;\n}, EventEmitter.prototype.off = function (e, t) {\n  if (void 0 === e) this._listeners = {};else if (void 0 === t) this._listeners[e] = [];else for (var a = this._listeners[e], r = 0; r < a.length;) {\n    a[r].fn === t ? a.splice(r, 1) : ++r;\n  }\n  return this;\n}, EventEmitter.prototype.emit = function (e) {\n  var t = this._listeners[e];\n\n  if (t) {\n    for (var a = [], r = 1; r < arguments.length;) {\n      a.push(arguments[r++]);\n    }\n\n    for (r = 0; r < t.length;) {\n      t[r].fn.apply(t[r++].ctx, a);\n    }\n  }\n\n  return this;\n};\nvar float_1 = factory(factory);\n\nfunction factory(e) {\n  return \"undefined\" != typeof Float32Array ? function () {\n    var t = new Float32Array([-0]),\n        a = new Uint8Array(t.buffer),\n        r = 128 === a[3];\n\n    function n(e, r, n) {\n      t[0] = e, r[n] = a[0], r[n + 1] = a[1], r[n + 2] = a[2], r[n + 3] = a[3];\n    }\n\n    function o(e, r, n) {\n      t[0] = e, r[n] = a[3], r[n + 1] = a[2], r[n + 2] = a[1], r[n + 3] = a[0];\n    }\n\n    function s(e, r) {\n      return a[0] = e[r], a[1] = e[r + 1], a[2] = e[r + 2], a[3] = e[r + 3], t[0];\n    }\n\n    function i(e, r) {\n      return a[3] = e[r], a[2] = e[r + 1], a[1] = e[r + 2], a[0] = e[r + 3], t[0];\n    }\n\n    e.writeFloatLE = r ? n : o, e.writeFloatBE = r ? o : n, e.readFloatLE = r ? s : i, e.readFloatBE = r ? i : s;\n  }() : function () {\n    function t(e, t, a, r) {\n      var n = t < 0 ? 1 : 0;\n      if (n && (t = -t), 0 === t) e(1 / t > 0 ? 0 : 2147483648, a, r);else if (isNaN(t)) e(2143289344, a, r);else if (t > 3.4028234663852886e38) e((n << 31 | 2139095040) >>> 0, a, r);else if (t < 1.1754943508222875e-38) e((n << 31 | Math.round(t / 1.401298464324817e-45)) >>> 0, a, r);else {\n        var o = Math.floor(Math.log(t) / Math.LN2);\n        e((n << 31 | o + 127 << 23 | 8388607 & Math.round(t * Math.pow(2, -o) * 8388608)) >>> 0, a, r);\n      }\n    }\n\n    function a(e, t, a) {\n      var r = e(t, a),\n          n = 2 * (r >> 31) + 1,\n          o = r >>> 23 & 255,\n          s = 8388607 & r;\n      return 255 === o ? s ? NaN : n * (1 / 0) : 0 === o ? 1.401298464324817e-45 * n * s : n * Math.pow(2, o - 150) * (s + 8388608);\n    }\n\n    e.writeFloatLE = t.bind(null, writeUintLE), e.writeFloatBE = t.bind(null, writeUintBE), e.readFloatLE = a.bind(null, readUintLE), e.readFloatBE = a.bind(null, readUintBE);\n  }(), \"undefined\" != typeof Float64Array ? function () {\n    var t = new Float64Array([-0]),\n        a = new Uint8Array(t.buffer),\n        r = 128 === a[7];\n\n    function n(e, r, n) {\n      t[0] = e, r[n] = a[0], r[n + 1] = a[1], r[n + 2] = a[2], r[n + 3] = a[3], r[n + 4] = a[4], r[n + 5] = a[5], r[n + 6] = a[6], r[n + 7] = a[7];\n    }\n\n    function o(e, r, n) {\n      t[0] = e, r[n] = a[7], r[n + 1] = a[6], r[n + 2] = a[5], r[n + 3] = a[4], r[n + 4] = a[3], r[n + 5] = a[2], r[n + 6] = a[1], r[n + 7] = a[0];\n    }\n\n    function s(e, r) {\n      return a[0] = e[r], a[1] = e[r + 1], a[2] = e[r + 2], a[3] = e[r + 3], a[4] = e[r + 4], a[5] = e[r + 5], a[6] = e[r + 6], a[7] = e[r + 7], t[0];\n    }\n\n    function i(e, r) {\n      return a[7] = e[r], a[6] = e[r + 1], a[5] = e[r + 2], a[4] = e[r + 3], a[3] = e[r + 4], a[2] = e[r + 5], a[1] = e[r + 6], a[0] = e[r + 7], t[0];\n    }\n\n    e.writeDoubleLE = r ? n : o, e.writeDoubleBE = r ? o : n, e.readDoubleLE = r ? s : i, e.readDoubleBE = r ? i : s;\n  }() : function () {\n    function t(e, t, a, r, n, o) {\n      var s = r < 0 ? 1 : 0;\n      if (s && (r = -r), 0 === r) e(0, n, o + t), e(1 / r > 0 ? 0 : 2147483648, n, o + a);else if (isNaN(r)) e(0, n, o + t), e(2146959360, n, o + a);else if (r > 1.7976931348623157e308) e(0, n, o + t), e((s << 31 | 2146435072) >>> 0, n, o + a);else {\n        var i;\n        if (r < 2.2250738585072014e-308) e((i = r / 5e-324) >>> 0, n, o + t), e((s << 31 | i / 4294967296) >>> 0, n, o + a);else {\n          var p = Math.floor(Math.log(r) / Math.LN2);\n          1024 === p && (p = 1023), e(4503599627370496 * (i = r * Math.pow(2, -p)) >>> 0, n, o + t), e((s << 31 | p + 1023 << 20 | 1048576 * i & 1048575) >>> 0, n, o + a);\n        }\n      }\n    }\n\n    function a(e, t, a, r, n) {\n      var o = e(r, n + t),\n          s = e(r, n + a),\n          i = 2 * (s >> 31) + 1,\n          p = s >>> 20 & 2047,\n          u = 4294967296 * (1048575 & s) + o;\n      return 2047 === p ? u ? NaN : i * (1 / 0) : 0 === p ? 5e-324 * i * u : i * Math.pow(2, p - 1075) * (u + 4503599627370496);\n    }\n\n    e.writeDoubleLE = t.bind(null, writeUintLE, 0, 4), e.writeDoubleBE = t.bind(null, writeUintBE, 4, 0), e.readDoubleLE = a.bind(null, readUintLE, 0, 4), e.readDoubleBE = a.bind(null, readUintBE, 4, 0);\n  }(), e;\n}\n\nfunction writeUintLE(e, t, a) {\n  t[a] = 255 & e, t[a + 1] = e >>> 8 & 255, t[a + 2] = e >>> 16 & 255, t[a + 3] = e >>> 24;\n}\n\nfunction writeUintBE(e, t, a) {\n  t[a] = e >>> 24, t[a + 1] = e >>> 16 & 255, t[a + 2] = e >>> 8 & 255, t[a + 3] = 255 & e;\n}\n\nfunction readUintLE(e, t) {\n  return (e[t] | e[t + 1] << 8 | e[t + 2] << 16 | e[t + 3] << 24) >>> 0;\n}\n\nfunction readUintBE(e, t) {\n  return (e[t] << 24 | e[t + 1] << 16 | e[t + 2] << 8 | e[t + 3]) >>> 0;\n}\n\nvar inquire_1 = inquire;\n\nfunction inquire(moduleName) {\n  try {\n    var mod$$1 = eval(\"quire\".replace(/^/, \"re\"))(moduleName);\n    if (mod$$1 && (mod$$1.length || Object.keys(mod$$1).length)) return mod$$1;\n  } catch (e) {}\n\n  return null;\n}\n\nvar utf8_1 = createCommonjsModule(function (e, t) {\n  var a = t;\n  a.length = function (e) {\n    for (var t = 0, a = 0, r = 0; r < e.length; ++r) {\n      (a = e.charCodeAt(r)) < 128 ? t += 1 : a < 2048 ? t += 2 : 55296 == (64512 & a) && 56320 == (64512 & e.charCodeAt(r + 1)) ? (++r, t += 4) : t += 3;\n    }\n\n    return t;\n  }, a.read = function (e, t, a) {\n    if (a - t < 1) return \"\";\n\n    for (var r, n = null, o = [], s = 0; t < a;) {\n      (r = e[t++]) < 128 ? o[s++] = r : r > 191 && r < 224 ? o[s++] = (31 & r) << 6 | 63 & e[t++] : r > 239 && r < 365 ? (r = ((7 & r) << 18 | (63 & e[t++]) << 12 | (63 & e[t++]) << 6 | 63 & e[t++]) - 65536, o[s++] = 55296 + (r >> 10), o[s++] = 56320 + (1023 & r)) : o[s++] = (15 & r) << 12 | (63 & e[t++]) << 6 | 63 & e[t++], s > 8191 && ((n || (n = [])).push(String.fromCharCode.apply(String, o)), s = 0);\n    }\n\n    return n ? (s && n.push(String.fromCharCode.apply(String, o.slice(0, s))), n.join(\"\")) : String.fromCharCode.apply(String, o.slice(0, s));\n  }, a.write = function (e, t, a) {\n    for (var r, n, o = a, s = 0; s < e.length; ++s) {\n      (r = e.charCodeAt(s)) < 128 ? t[a++] = r : r < 2048 ? (t[a++] = r >> 6 | 192, t[a++] = 63 & r | 128) : 55296 == (64512 & r) && 56320 == (64512 & (n = e.charCodeAt(s + 1))) ? (r = 65536 + ((1023 & r) << 10) + (1023 & n), ++s, t[a++] = r >> 18 | 240, t[a++] = r >> 12 & 63 | 128, t[a++] = r >> 6 & 63 | 128, t[a++] = 63 & r | 128) : (t[a++] = r >> 12 | 224, t[a++] = r >> 6 & 63 | 128, t[a++] = 63 & r | 128);\n    }\n\n    return a - o;\n  };\n}),\n    pool_1 = pool;\n\nfunction pool(e, t, a) {\n  var r = a || 8192,\n      n = r >>> 1,\n      o = null,\n      s = r;\n  return function (a) {\n    if (a < 1 || a > n) return e(a);\n    s + a > r && (o = e(r), s = 0);\n    var i = t.call(o, s, s += a);\n    return 7 & s && (s = 1 + (7 | s)), i;\n  };\n}\n\nvar longbits = LongBits;\n\nfunction LongBits(e, t) {\n  this.lo = e >>> 0, this.hi = t >>> 0;\n}\n\nvar zero = LongBits.zero = new LongBits(0, 0);\nzero.toNumber = function () {\n  return 0;\n}, zero.zzEncode = zero.zzDecode = function () {\n  return this;\n}, zero.length = function () {\n  return 1;\n};\nvar zeroHash = LongBits.zeroHash = \"\\0\\0\\0\\0\\0\\0\\0\\0\";\nLongBits.fromNumber = function (e) {\n  if (0 === e) return zero;\n  var t = e < 0;\n  t && (e = -e);\n  var a = e >>> 0,\n      r = (e - a) / 4294967296 >>> 0;\n  return t && (r = ~r >>> 0, a = ~a >>> 0, ++a > 4294967295 && (a = 0, ++r > 4294967295 && (r = 0))), new LongBits(a, r);\n}, LongBits.from = function (e) {\n  if (\"number\" == typeof e) return LongBits.fromNumber(e);\n\n  if (minimal.isString(e)) {\n    if (!minimal.Long) return LongBits.fromNumber(parseInt(e, 10));\n    e = minimal.Long.fromString(e);\n  }\n\n  return e.low || e.high ? new LongBits(e.low >>> 0, e.high >>> 0) : zero;\n}, LongBits.prototype.toNumber = function (e) {\n  if (!e && this.hi >>> 31) {\n    var t = 1 + ~this.lo >>> 0,\n        a = ~this.hi >>> 0;\n    return t || (a = a + 1 >>> 0), -(t + 4294967296 * a);\n  }\n\n  return this.lo + 4294967296 * this.hi;\n}, LongBits.prototype.toLong = function (e) {\n  return minimal.Long ? new minimal.Long(0 | this.lo, 0 | this.hi, Boolean(e)) : {\n    low: 0 | this.lo,\n    high: 0 | this.hi,\n    unsigned: Boolean(e)\n  };\n};\nvar charCodeAt = String.prototype.charCodeAt;\nLongBits.fromHash = function (e) {\n  return e === zeroHash ? zero : new LongBits((charCodeAt.call(e, 0) | charCodeAt.call(e, 1) << 8 | charCodeAt.call(e, 2) << 16 | charCodeAt.call(e, 3) << 24) >>> 0, (charCodeAt.call(e, 4) | charCodeAt.call(e, 5) << 8 | charCodeAt.call(e, 6) << 16 | charCodeAt.call(e, 7) << 24) >>> 0);\n}, LongBits.prototype.toHash = function () {\n  return String.fromCharCode(255 & this.lo, this.lo >>> 8 & 255, this.lo >>> 16 & 255, this.lo >>> 24, 255 & this.hi, this.hi >>> 8 & 255, this.hi >>> 16 & 255, this.hi >>> 24);\n}, LongBits.prototype.zzEncode = function () {\n  var e = this.hi >> 31;\n  return this.hi = ((this.hi << 1 | this.lo >>> 31) ^ e) >>> 0, this.lo = (this.lo << 1 ^ e) >>> 0, this;\n}, LongBits.prototype.zzDecode = function () {\n  var e = -(1 & this.lo);\n  return this.lo = ((this.lo >>> 1 | this.hi << 31) ^ e) >>> 0, this.hi = (this.hi >>> 1 ^ e) >>> 0, this;\n}, LongBits.prototype.length = function () {\n  var e = this.lo,\n      t = (this.lo >>> 28 | this.hi << 4) >>> 0,\n      a = this.hi >>> 24;\n  return 0 === a ? 0 === t ? e < 16384 ? e < 128 ? 1 : 2 : e < 2097152 ? 3 : 4 : t < 16384 ? t < 128 ? 5 : 6 : t < 2097152 ? 7 : 8 : a < 128 ? 9 : 10;\n};\nvar minimal = createCommonjsModule(function (e, t) {\n  var a = t;\n\n  function r(e, t, a) {\n    for (var r = Object.keys(t), n = 0; n < r.length; ++n) {\n      void 0 !== e[r[n]] && a || (e[r[n]] = t[r[n]]);\n    }\n\n    return e;\n  }\n\n  function n(e) {\n    function t(e, a) {\n      if (!(this instanceof t)) return new t(e, a);\n      Object.defineProperty(this, \"message\", {\n        get: function get() {\n          return e;\n        }\n      }), Error.captureStackTrace ? Error.captureStackTrace(this, t) : Object.defineProperty(this, \"stack\", {\n        value: new Error().stack || \"\"\n      }), a && r(this, a);\n    }\n\n    return (t.prototype = Object.create(Error.prototype)).constructor = t, Object.defineProperty(t.prototype, \"name\", {\n      get: function get() {\n        return e;\n      }\n    }), t.prototype.toString = function () {\n      return this.name + \": \" + this.message;\n    }, t;\n  }\n\n  a.asPromise = aspromise, a.base64 = base64_1, a.EventEmitter = eventemitter, a.float = float_1, a.inquire = inquire_1, a.utf8 = utf8_1, a.pool = pool_1, a.LongBits = longbits, a.global = \"undefined\" != typeof window && window || void 0 !== commonjsGlobal && commonjsGlobal || \"undefined\" != typeof self && self || commonjsGlobal, a.emptyArray = Object.freeze ? Object.freeze([]) : [], a.emptyObject = Object.freeze ? Object.freeze({}) : {}, a.isNode = Boolean(a.global.process && a.global.process.versions && a.global.process.versions.node), a.isInteger = Number.isInteger || function (e) {\n    return \"number\" == typeof e && isFinite(e) && Math.floor(e) === e;\n  }, a.isString = function (e) {\n    return \"string\" == typeof e || e instanceof String;\n  }, a.isObject = function (e) {\n    return e && \"object\" == typeof e;\n  }, a.isset = a.isSet = function (e, t) {\n    var a = e[t];\n    return !(null == a || !e.hasOwnProperty(t)) && (\"object\" != typeof a || (Array.isArray(a) ? a.length : Object.keys(a).length) > 0);\n  }, a.Buffer = function () {\n    try {\n      var e = a.inquire(\"buffer\").Buffer;\n      return e.prototype.utf8Write ? e : null;\n    } catch (e) {\n      return null;\n    }\n  }(), a._Buffer_from = null, a._Buffer_allocUnsafe = null, a.newBuffer = function (e) {\n    return \"number\" == typeof e ? a.Buffer ? a._Buffer_allocUnsafe(e) : new a.Array(e) : a.Buffer ? a._Buffer_from(e) : \"undefined\" == typeof Uint8Array ? e : new Uint8Array(e);\n  }, a.Array = \"undefined\" != typeof Uint8Array ? Uint8Array : Array, a.Long = a.global.dcodeIO && a.global.dcodeIO.Long || a.global.Long || a.inquire(\"long\"), a.key2Re = /^true|false|0|1$/, a.key32Re = /^-?(?:0|[1-9][0-9]*)$/, a.key64Re = /^(?:[\\\\x00-\\\\xff]{8}|-?(?:0|[1-9][0-9]*))$/, a.longToHash = function (e) {\n    return e ? a.LongBits.from(e).toHash() : a.LongBits.zeroHash;\n  }, a.longFromHash = function (e, t) {\n    var r = a.LongBits.fromHash(e);\n    return a.Long ? a.Long.fromBits(r.lo, r.hi, t) : r.toNumber(Boolean(t));\n  }, a.merge = r, a.lcFirst = function (e) {\n    return e.charAt(0).toLowerCase() + e.substring(1);\n  }, a.newError = n, a.ProtocolError = n(\"ProtocolError\"), a.oneOfGetter = function (e) {\n    for (var t = {}, a = 0; a < e.length; ++a) {\n      t[e[a]] = 1;\n    }\n\n    return function () {\n      for (var e = Object.keys(this), a = e.length - 1; a > -1; --a) {\n        if (1 === t[e[a]] && void 0 !== this[e[a]] && null !== this[e[a]]) return e[a];\n      }\n    };\n  }, a.oneOfSetter = function (e) {\n    return function (t) {\n      for (var a = 0; a < e.length; ++a) {\n        e[a] !== t && delete this[e[a]];\n      }\n    };\n  }, a.toJSONOptions = {\n    longs: String,\n    enums: String,\n    bytes: String,\n    json: !0\n  }, a._configure = function () {\n    var e = a.Buffer;\n    e ? (a._Buffer_from = e.from !== Uint8Array.from && e.from || function (t, a) {\n      return new e(t, a);\n    }, a._Buffer_allocUnsafe = e.allocUnsafe || function (t) {\n      return new e(t);\n    }) : a._Buffer_from = a._Buffer_allocUnsafe = null;\n  };\n}),\n    writer = Writer,\n    BufferWriter,\n    LongBits$1 = minimal.LongBits,\n    base64 = minimal.base64,\n    utf8 = minimal.utf8;\n\nfunction Op(e, t, a) {\n  this.fn = e, this.len = t, this.next = void 0, this.val = a;\n}\n\nfunction noop() {}\n\nfunction State(e) {\n  this.head = e.head, this.tail = e.tail, this.len = e.len, this.next = e.states;\n}\n\nfunction Writer() {\n  this.len = 0, this.head = new Op(noop, 0, 0), this.tail = this.head, this.states = null;\n}\n\nfunction writeByte(e, t, a) {\n  t[a] = 255 & e;\n}\n\nfunction writeVarint32(e, t, a) {\n  for (; e > 127;) {\n    t[a++] = 127 & e | 128, e >>>= 7;\n  }\n\n  t[a] = e;\n}\n\nfunction VarintOp(e, t) {\n  this.len = e, this.next = void 0, this.val = t;\n}\n\nfunction writeVarint64(e, t, a) {\n  for (; e.hi;) {\n    t[a++] = 127 & e.lo | 128, e.lo = (e.lo >>> 7 | e.hi << 25) >>> 0, e.hi >>>= 7;\n  }\n\n  for (; e.lo > 127;) {\n    t[a++] = 127 & e.lo | 128, e.lo = e.lo >>> 7;\n  }\n\n  t[a++] = e.lo;\n}\n\nfunction writeFixed32(e, t, a) {\n  t[a] = 255 & e, t[a + 1] = e >>> 8 & 255, t[a + 2] = e >>> 16 & 255, t[a + 3] = e >>> 24;\n}\n\nWriter.create = minimal.Buffer ? function () {\n  return (Writer.create = function () {\n    return new BufferWriter();\n  })();\n} : function () {\n  return new Writer();\n}, Writer.alloc = function (e) {\n  return new minimal.Array(e);\n}, minimal.Array !== Array && (Writer.alloc = minimal.pool(Writer.alloc, minimal.Array.prototype.subarray)), Writer.prototype._push = function (e, t, a) {\n  return this.tail = this.tail.next = new Op(e, t, a), this.len += t, this;\n}, VarintOp.prototype = Object.create(Op.prototype), VarintOp.prototype.fn = writeVarint32, Writer.prototype.uint32 = function (e) {\n  return this.len += (this.tail = this.tail.next = new VarintOp((e >>>= 0) < 128 ? 1 : e < 16384 ? 2 : e < 2097152 ? 3 : e < 268435456 ? 4 : 5, e)).len, this;\n}, Writer.prototype.int32 = function (e) {\n  return e < 0 ? this._push(writeVarint64, 10, LongBits$1.fromNumber(e)) : this.uint32(e);\n}, Writer.prototype.sint32 = function (e) {\n  return this.uint32((e << 1 ^ e >> 31) >>> 0);\n}, Writer.prototype.uint64 = function (e) {\n  var t = LongBits$1.from(e);\n  return this._push(writeVarint64, t.length(), t);\n}, Writer.prototype.int64 = Writer.prototype.uint64, Writer.prototype.sint64 = function (e) {\n  var t = LongBits$1.from(e).zzEncode();\n  return this._push(writeVarint64, t.length(), t);\n}, Writer.prototype.bool = function (e) {\n  return this._push(writeByte, 1, e ? 1 : 0);\n}, Writer.prototype.fixed32 = function (e) {\n  return this._push(writeFixed32, 4, e >>> 0);\n}, Writer.prototype.sfixed32 = Writer.prototype.fixed32, Writer.prototype.fixed64 = function (e) {\n  var t = LongBits$1.from(e);\n  return this._push(writeFixed32, 4, t.lo)._push(writeFixed32, 4, t.hi);\n}, Writer.prototype.sfixed64 = Writer.prototype.fixed64, Writer.prototype.float = function (e) {\n  return this._push(minimal.float.writeFloatLE, 4, e);\n}, Writer.prototype.double = function (e) {\n  return this._push(minimal.float.writeDoubleLE, 8, e);\n};\nvar writeBytes = minimal.Array.prototype.set ? function (e, t, a) {\n  t.set(e, a);\n} : function (e, t, a) {\n  for (var r = 0; r < e.length; ++r) {\n    t[a + r] = e[r];\n  }\n};\nWriter.prototype.bytes = function (e) {\n  var t = e.length >>> 0;\n  if (!t) return this._push(writeByte, 1, 0);\n\n  if (minimal.isString(e)) {\n    var a = Writer.alloc(t = base64.length(e));\n    base64.decode(e, a, 0), e = a;\n  }\n\n  return this.uint32(t)._push(writeBytes, t, e);\n}, Writer.prototype.string = function (e) {\n  var t = utf8.length(e);\n  return t ? this.uint32(t)._push(utf8.write, t, e) : this._push(writeByte, 1, 0);\n}, Writer.prototype.fork = function () {\n  return this.states = new State(this), this.head = this.tail = new Op(noop, 0, 0), this.len = 0, this;\n}, Writer.prototype.reset = function () {\n  return this.states ? (this.head = this.states.head, this.tail = this.states.tail, this.len = this.states.len, this.states = this.states.next) : (this.head = this.tail = new Op(noop, 0, 0), this.len = 0), this;\n}, Writer.prototype.ldelim = function () {\n  var e = this.head,\n      t = this.tail,\n      a = this.len;\n  return this.reset().uint32(a), a && (this.tail.next = e.next, this.tail = t, this.len += a), this;\n}, Writer.prototype.finish = function () {\n  for (var e = this.head.next, t = this.constructor.alloc(this.len), a = 0; e;) {\n    e.fn(e.val, t, a), a += e.len, e = e.next;\n  }\n\n  return t;\n}, Writer._configure = function (e) {\n  BufferWriter = e;\n};\nvar writer_buffer = BufferWriter$1;\n(BufferWriter$1.prototype = Object.create(writer.prototype)).constructor = BufferWriter$1;\nvar Buffer$1 = minimal.Buffer;\n\nfunction BufferWriter$1() {\n  writer.call(this);\n}\n\nBufferWriter$1.alloc = function (e) {\n  return (BufferWriter$1.alloc = minimal._Buffer_allocUnsafe)(e);\n};\n\nvar writeBytesBuffer = Buffer$1 && Buffer$1.prototype instanceof Uint8Array && \"set\" === Buffer$1.prototype.set.name ? function (e, t, a) {\n  t.set(e, a);\n} : function (e, t, a) {\n  if (e.copy) e.copy(t, a, 0, e.length);else for (var r = 0; r < e.length;) {\n    t[a++] = e[r++];\n  }\n};\n\nfunction writeStringBuffer(e, t, a) {\n  e.length < 40 ? minimal.utf8.write(e, t, a) : t.utf8Write(e, a);\n}\n\nBufferWriter$1.prototype.bytes = function (e) {\n  minimal.isString(e) && (e = minimal._Buffer_from(e, \"base64\"));\n  var t = e.length >>> 0;\n  return this.uint32(t), t && this._push(writeBytesBuffer, t, e), this;\n}, BufferWriter$1.prototype.string = function (e) {\n  var t = Buffer$1.byteLength(e);\n  return this.uint32(t), t && this._push(writeStringBuffer, t, e), this;\n};\nvar reader = Reader,\n    BufferReader,\n    LongBits$2 = minimal.LongBits,\n    utf8$1 = minimal.utf8;\n\nfunction indexOutOfRange(e, t) {\n  return RangeError(\"index out of range: \" + e.pos + \" + \" + (t || 1) + \" > \" + e.len);\n}\n\nfunction Reader(e) {\n  this.buf = e, this.pos = 0, this.len = e.length;\n}\n\nvar create_array = \"undefined\" != typeof Uint8Array ? function (e) {\n  if (e instanceof Uint8Array || Array.isArray(e)) return new Reader(e);\n  throw Error(\"illegal buffer\");\n} : function (e) {\n  if (Array.isArray(e)) return new Reader(e);\n  throw Error(\"illegal buffer\");\n};\n\nfunction readLongVarint() {\n  var e = new LongBits$2(0, 0),\n      t = 0;\n\n  if (!(this.len - this.pos > 4)) {\n    for (; t < 3; ++t) {\n      if (this.pos >= this.len) throw indexOutOfRange(this);\n      if (e.lo = (e.lo | (127 & this.buf[this.pos]) << 7 * t) >>> 0, this.buf[this.pos++] < 128) return e;\n    }\n\n    return e.lo = (e.lo | (127 & this.buf[this.pos++]) << 7 * t) >>> 0, e;\n  }\n\n  for (; t < 4; ++t) {\n    if (e.lo = (e.lo | (127 & this.buf[this.pos]) << 7 * t) >>> 0, this.buf[this.pos++] < 128) return e;\n  }\n\n  if (e.lo = (e.lo | (127 & this.buf[this.pos]) << 28) >>> 0, e.hi = (e.hi | (127 & this.buf[this.pos]) >> 4) >>> 0, this.buf[this.pos++] < 128) return e;\n\n  if (t = 0, this.len - this.pos > 4) {\n    for (; t < 5; ++t) {\n      if (e.hi = (e.hi | (127 & this.buf[this.pos]) << 7 * t + 3) >>> 0, this.buf[this.pos++] < 128) return e;\n    }\n  } else for (; t < 5; ++t) {\n    if (this.pos >= this.len) throw indexOutOfRange(this);\n    if (e.hi = (e.hi | (127 & this.buf[this.pos]) << 7 * t + 3) >>> 0, this.buf[this.pos++] < 128) return e;\n  }\n\n  throw Error(\"invalid varint encoding\");\n}\n\nfunction readFixed32_end(e, t) {\n  return (e[t - 4] | e[t - 3] << 8 | e[t - 2] << 16 | e[t - 1] << 24) >>> 0;\n}\n\nfunction readFixed64() {\n  if (this.pos + 8 > this.len) throw indexOutOfRange(this, 8);\n  return new LongBits$2(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));\n}\n\nReader.create = minimal.Buffer ? function (e) {\n  return (Reader.create = function (e) {\n    return minimal.Buffer.isBuffer(e) ? new BufferReader(e) : create_array(e);\n  })(e);\n} : create_array, Reader.prototype._slice = minimal.Array.prototype.subarray || minimal.Array.prototype.slice, Reader.prototype.uint32 = function () {\n  var e = 4294967295;\n  return function () {\n    if (e = (127 & this.buf[this.pos]) >>> 0, this.buf[this.pos++] < 128) return e;\n    if (e = (e | (127 & this.buf[this.pos]) << 7) >>> 0, this.buf[this.pos++] < 128) return e;\n    if (e = (e | (127 & this.buf[this.pos]) << 14) >>> 0, this.buf[this.pos++] < 128) return e;\n    if (e = (e | (127 & this.buf[this.pos]) << 21) >>> 0, this.buf[this.pos++] < 128) return e;\n    if (e = (e | (15 & this.buf[this.pos]) << 28) >>> 0, this.buf[this.pos++] < 128) return e;\n    if ((this.pos += 5) > this.len) throw this.pos = this.len, indexOutOfRange(this, 10);\n    return e;\n  };\n}(), Reader.prototype.int32 = function () {\n  return 0 | this.uint32();\n}, Reader.prototype.sint32 = function () {\n  var e = this.uint32();\n  return e >>> 1 ^ -(1 & e) | 0;\n}, Reader.prototype.bool = function () {\n  return 0 !== this.uint32();\n}, Reader.prototype.fixed32 = function () {\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  return readFixed32_end(this.buf, this.pos += 4);\n}, Reader.prototype.sfixed32 = function () {\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  return 0 | readFixed32_end(this.buf, this.pos += 4);\n}, Reader.prototype.float = function () {\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  var e = minimal.float.readFloatLE(this.buf, this.pos);\n  return this.pos += 4, e;\n}, Reader.prototype.double = function () {\n  if (this.pos + 8 > this.len) throw indexOutOfRange(this, 4);\n  var e = minimal.float.readDoubleLE(this.buf, this.pos);\n  return this.pos += 8, e;\n}, Reader.prototype.bytes = function () {\n  var e = this.uint32(),\n      t = this.pos,\n      a = this.pos + e;\n  if (a > this.len) throw indexOutOfRange(this, e);\n  return this.pos += e, Array.isArray(this.buf) ? this.buf.slice(t, a) : t === a ? new this.buf.constructor(0) : this._slice.call(this.buf, t, a);\n}, Reader.prototype.string = function () {\n  var e = this.bytes();\n  return utf8$1.read(e, 0, e.length);\n}, Reader.prototype.skip = function (e) {\n  if (\"number\" == typeof e) {\n    if (this.pos + e > this.len) throw indexOutOfRange(this, e);\n    this.pos += e;\n  } else do {\n    if (this.pos >= this.len) throw indexOutOfRange(this);\n  } while (128 & this.buf[this.pos++]);\n\n  return this;\n}, Reader.prototype.skipType = function (e) {\n  switch (e) {\n    case 0:\n      this.skip();\n      break;\n\n    case 1:\n      this.skip(8);\n      break;\n\n    case 2:\n      this.skip(this.uint32());\n      break;\n\n    case 3:\n      for (; 4 != (e = 7 & this.uint32());) {\n        this.skipType(e);\n      }\n\n      break;\n\n    case 5:\n      this.skip(4);\n      break;\n\n    default:\n      throw Error(\"invalid wire type \" + e + \" at offset \" + this.pos);\n  }\n\n  return this;\n}, Reader._configure = function (e) {\n  BufferReader = e;\n  var t = minimal.Long ? \"toLong\" : \"toNumber\";\n  minimal.merge(Reader.prototype, {\n    int64: function int64() {\n      return readLongVarint.call(this)[t](!1);\n    },\n    uint64: function uint64() {\n      return readLongVarint.call(this)[t](!0);\n    },\n    sint64: function sint64() {\n      return readLongVarint.call(this).zzDecode()[t](!1);\n    },\n    fixed64: function fixed64() {\n      return readFixed64.call(this)[t](!0);\n    },\n    sfixed64: function sfixed64() {\n      return readFixed64.call(this)[t](!1);\n    }\n  });\n};\nvar reader_buffer = BufferReader$1;\n\nfunction BufferReader$1(e) {\n  reader.call(this, e);\n}\n\n(BufferReader$1.prototype = Object.create(reader.prototype)).constructor = BufferReader$1, minimal.Buffer && (BufferReader$1.prototype._slice = minimal.Buffer.prototype.slice), BufferReader$1.prototype.string = function () {\n  var e = this.uint32();\n  return this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + e, this.len));\n};\nvar service = Service;\n\nfunction Service(e, t, a) {\n  if (\"function\" != typeof e) throw TypeError(\"rpcImpl must be a function\");\n  minimal.EventEmitter.call(this), this.rpcImpl = e, this.requestDelimited = Boolean(t), this.responseDelimited = Boolean(a);\n}\n\n(Service.prototype = Object.create(minimal.EventEmitter.prototype)).constructor = Service, Service.prototype.rpcCall = function e(t, a, r, n, o) {\n  if (!n) throw TypeError(\"request must be specified\");\n  var s = this;\n  if (!o) return minimal.asPromise(e, s, t, a, r, n);\n  if (s.rpcImpl) try {\n    return s.rpcImpl(t, a[s.requestDelimited ? \"encodeDelimited\" : \"encode\"](n).finish(), function (e, a) {\n      if (e) return s.emit(\"error\", e, t), o(e);\n\n      if (null !== a) {\n        if (!(a instanceof r)) try {\n          a = r[s.responseDelimited ? \"decodeDelimited\" : \"decode\"](a);\n        } catch (e) {\n          return s.emit(\"error\", e, t), o(e);\n        }\n        return s.emit(\"data\", a, t), o(null, a);\n      }\n\n      s.end(!0);\n    });\n  } catch (e) {\n    return s.emit(\"error\", e, t), void setTimeout(function () {\n      o(e);\n    }, 0);\n  } else setTimeout(function () {\n    o(Error(\"already ended\"));\n  }, 0);\n}, Service.prototype.end = function (e) {\n  return this.rpcImpl && (e || this.rpcImpl(null, null, null), this.rpcImpl = null, this.emit(\"end\").off()), this;\n};\nvar rpc_1 = createCommonjsModule(function (e, t) {\n  t.Service = service;\n}),\n    roots = {},\n    indexMinimal = createCommonjsModule(function (e, t) {\n  var a = t;\n\n  function r() {\n    a.Reader._configure(a.BufferReader), a.util._configure();\n  }\n\n  a.build = \"minimal\", a.Writer = writer, a.BufferWriter = writer_buffer, a.Reader = reader, a.BufferReader = reader_buffer, a.util = minimal, a.rpc = rpc_1, a.roots = roots, a.configure = r, a.Writer._configure(a.BufferWriter), r();\n}),\n    minimal$1 = indexMinimal,\n    minimal_1 = minimal$1.roots,\n    minimal_2 = minimal$1.Reader,\n    minimal_3 = minimal$1.util,\n    $Reader = minimal$1.Reader,\n    $util = minimal$1.util,\n    $root = minimal$1.roots.default || (minimal$1.roots.default = {});\n\n$root.tensorflow = function () {\n  var e,\n      t,\n      a = {};\n  return a.Any = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.typeUrl = \"\", e.prototype.value = $util.newBuffer([]), e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.Any(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.typeUrl = e.string();\n            break;\n\n          case 2:\n            r.value = e.bytes();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.DataType = (e = {}, (t = Object.create(e))[e[0] = \"DT_INVALID\"] = 0, t[e[1] = \"DT_FLOAT\"] = 1, t[e[2] = \"DT_DOUBLE\"] = 2, t[e[3] = \"DT_INT32\"] = 3, t[e[4] = \"DT_UINT8\"] = 4, t[e[5] = \"DT_INT16\"] = 5, t[e[6] = \"DT_INT8\"] = 6, t[e[7] = \"DT_STRING\"] = 7, t[e[8] = \"DT_COMPLEX64\"] = 8, t[e[9] = \"DT_INT64\"] = 9, t[e[10] = \"DT_BOOL\"] = 10, t[e[11] = \"DT_QINT8\"] = 11, t[e[12] = \"DT_QUINT8\"] = 12, t[e[13] = \"DT_QINT32\"] = 13, t[e[14] = \"DT_BFLOAT16\"] = 14, t[e[101] = \"DT_FLOAT_REF\"] = 101, t[e[102] = \"DT_DOUBLE_REF\"] = 102, t[e[103] = \"DT_INT32_REF\"] = 103, t[e[104] = \"DT_UINT8_REF\"] = 104, t[e[105] = \"DT_INT16_REF\"] = 105, t[e[106] = \"DT_INT8_REF\"] = 106, t[e[107] = \"DT_STRING_REF\"] = 107, t[e[108] = \"DT_COMPLEX64_REF\"] = 108, t[e[109] = \"DT_INT64_REF\"] = 109, t[e[110] = \"DT_BOOL_REF\"] = 110, t[e[111] = \"DT_QINT8_REF\"] = 111, t[e[112] = \"DT_QUINT8_REF\"] = 112, t[e[113] = \"DT_QINT32_REF\"] = 113, t[e[114] = \"DT_BFLOAT16_REF\"] = 114, t), a.TensorShape = function () {\n    function e(e) {\n      if (this.dim = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.dim = $util.emptyArray, e.prototype.unknownRank = !1, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.TensorShape(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 2:\n            r.dim && r.dim.length || (r.dim = []), r.dim.push($root.tensorflow.TensorShape.Dim.decode(e, e.uint32()));\n            break;\n\n          case 3:\n            r.unknownRank = e.bool();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.Dim = function () {\n      function e(e) {\n        if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.size = $util.Long ? $util.Long.fromBits(0, 0, !1) : 0, e.prototype.name = \"\", e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.TensorShape.Dim(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.size = e.int64();\n              break;\n\n            case 2:\n              r.name = e.string();\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.Tensor = function () {\n    function e(e) {\n      if (this.floatVal = [], this.doubleVal = [], this.intVal = [], this.stringVal = [], this.scomplexVal = [], this.int64Val = [], this.boolVal = [], this.uint32Val = [], this.uint64Val = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.dtype = 0, e.prototype.tensorShape = null, e.prototype.versionNumber = 0, e.prototype.tensorContent = $util.newBuffer([]), e.prototype.floatVal = $util.emptyArray, e.prototype.doubleVal = $util.emptyArray, e.prototype.intVal = $util.emptyArray, e.prototype.stringVal = $util.emptyArray, e.prototype.scomplexVal = $util.emptyArray, e.prototype.int64Val = $util.emptyArray, e.prototype.boolVal = $util.emptyArray, e.prototype.uint32Val = $util.emptyArray, e.prototype.uint64Val = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.Tensor(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.dtype = e.int32();\n            break;\n\n          case 2:\n            r.tensorShape = $root.tensorflow.TensorShape.decode(e, e.uint32());\n            break;\n\n          case 3:\n            r.versionNumber = e.int32();\n            break;\n\n          case 4:\n            r.tensorContent = e.bytes();\n            break;\n\n          case 5:\n            if (r.floatVal && r.floatVal.length || (r.floatVal = []), 2 == (7 & n)) for (var o = e.uint32() + e.pos; e.pos < o;) {\n              r.floatVal.push(e.float());\n            } else r.floatVal.push(e.float());\n            break;\n\n          case 6:\n            if (r.doubleVal && r.doubleVal.length || (r.doubleVal = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.doubleVal.push(e.double());\n            } else r.doubleVal.push(e.double());\n            break;\n\n          case 7:\n            if (r.intVal && r.intVal.length || (r.intVal = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.intVal.push(e.int32());\n            } else r.intVal.push(e.int32());\n            break;\n\n          case 8:\n            r.stringVal && r.stringVal.length || (r.stringVal = []), r.stringVal.push(e.bytes());\n            break;\n\n          case 9:\n            if (r.scomplexVal && r.scomplexVal.length || (r.scomplexVal = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.scomplexVal.push(e.float());\n            } else r.scomplexVal.push(e.float());\n            break;\n\n          case 10:\n            if (r.int64Val && r.int64Val.length || (r.int64Val = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.int64Val.push(e.int64());\n            } else r.int64Val.push(e.int64());\n            break;\n\n          case 11:\n            if (r.boolVal && r.boolVal.length || (r.boolVal = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.boolVal.push(e.bool());\n            } else r.boolVal.push(e.bool());\n            break;\n\n          case 16:\n            if (r.uint32Val && r.uint32Val.length || (r.uint32Val = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.uint32Val.push(e.uint32());\n            } else r.uint32Val.push(e.uint32());\n            break;\n\n          case 17:\n            if (r.uint64Val && r.uint64Val.length || (r.uint64Val = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n              r.uint64Val.push(e.uint64());\n            } else r.uint64Val.push(e.uint64());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.AttrValue = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    var t;\n    return e.prototype.list = null, e.prototype.s = $util.newBuffer([]), e.prototype.i = $util.Long ? $util.Long.fromBits(0, 0, !1) : 0, e.prototype.f = 0, e.prototype.b = !1, e.prototype.type = 0, e.prototype.shape = null, e.prototype.tensor = null, e.prototype.placeholder = \"\", e.prototype.func = null, Object.defineProperty(e.prototype, \"value\", {\n      get: $util.oneOfGetter(t = [\"list\", \"s\", \"i\", \"f\", \"b\", \"type\", \"shape\", \"tensor\", \"placeholder\", \"func\"]),\n      set: $util.oneOfSetter(t)\n    }), e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.AttrValue(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.list = $root.tensorflow.AttrValue.ListValue.decode(e, e.uint32());\n            break;\n\n          case 2:\n            r.s = e.bytes();\n            break;\n\n          case 3:\n            r.i = e.int64();\n            break;\n\n          case 4:\n            r.f = e.float();\n            break;\n\n          case 5:\n            r.b = e.bool();\n            break;\n\n          case 6:\n            r.type = e.int32();\n            break;\n\n          case 7:\n            r.shape = $root.tensorflow.TensorShape.decode(e, e.uint32());\n            break;\n\n          case 8:\n            r.tensor = $root.tensorflow.Tensor.decode(e, e.uint32());\n            break;\n\n          case 9:\n            r.placeholder = e.string();\n            break;\n\n          case 10:\n            r.func = $root.tensorflow.NameAttrList.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.ListValue = function () {\n      function e(e) {\n        if (this.s = [], this.i = [], this.f = [], this.b = [], this.type = [], this.shape = [], this.tensor = [], this.func = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.s = $util.emptyArray, e.prototype.i = $util.emptyArray, e.prototype.f = $util.emptyArray, e.prototype.b = $util.emptyArray, e.prototype.type = $util.emptyArray, e.prototype.shape = $util.emptyArray, e.prototype.tensor = $util.emptyArray, e.prototype.func = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.AttrValue.ListValue(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 2:\n              r.s && r.s.length || (r.s = []), r.s.push(e.bytes());\n              break;\n\n            case 3:\n              if (r.i && r.i.length || (r.i = []), 2 == (7 & n)) for (var o = e.uint32() + e.pos; e.pos < o;) {\n                r.i.push(e.int64());\n              } else r.i.push(e.int64());\n              break;\n\n            case 4:\n              if (r.f && r.f.length || (r.f = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n                r.f.push(e.float());\n              } else r.f.push(e.float());\n              break;\n\n            case 5:\n              if (r.b && r.b.length || (r.b = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n                r.b.push(e.bool());\n              } else r.b.push(e.bool());\n              break;\n\n            case 6:\n              if (r.type && r.type.length || (r.type = []), 2 == (7 & n)) for (o = e.uint32() + e.pos; e.pos < o;) {\n                r.type.push(e.int32());\n              } else r.type.push(e.int32());\n              break;\n\n            case 7:\n              r.shape && r.shape.length || (r.shape = []), r.shape.push($root.tensorflow.TensorShape.decode(e, e.uint32()));\n              break;\n\n            case 8:\n              r.tensor && r.tensor.length || (r.tensor = []), r.tensor.push($root.tensorflow.Tensor.decode(e, e.uint32()));\n              break;\n\n            case 9:\n              r.func && r.func.length || (r.func = []), r.func.push($root.tensorflow.NameAttrList.decode(e, e.uint32()));\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.NameAttrList = function () {\n    function e(e) {\n      if (this.attr = {}, e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.name = \"\", e.prototype.attr = $util.emptyObject, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a, r = void 0 === t ? e.len : e.pos + t, n = new $root.tensorflow.NameAttrList(); e.pos < r;) {\n        var o = e.uint32();\n\n        switch (o >>> 3) {\n          case 1:\n            n.name = e.string();\n            break;\n\n          case 2:\n            e.skip().pos++, n.attr === $util.emptyObject && (n.attr = {}), a = e.string(), e.pos++, n.attr[a] = $root.tensorflow.AttrValue.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & o);\n        }\n      }\n\n      return n;\n    }, e;\n  }(), a.NodeDef = function () {\n    function e(e) {\n      if (this.input = [], this.attr = {}, e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.name = \"\", e.prototype.op = \"\", e.prototype.input = $util.emptyArray, e.prototype.device = \"\", e.prototype.attr = $util.emptyObject, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a, r = void 0 === t ? e.len : e.pos + t, n = new $root.tensorflow.NodeDef(); e.pos < r;) {\n        var o = e.uint32();\n\n        switch (o >>> 3) {\n          case 1:\n            n.name = e.string();\n            break;\n\n          case 2:\n            n.op = e.string();\n            break;\n\n          case 3:\n            n.input && n.input.length || (n.input = []), n.input.push(e.string());\n            break;\n\n          case 4:\n            n.device = e.string();\n            break;\n\n          case 5:\n            e.skip().pos++, n.attr === $util.emptyObject && (n.attr = {}), a = e.string(), e.pos++, n.attr[a] = $root.tensorflow.AttrValue.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & o);\n        }\n      }\n\n      return n;\n    }, e;\n  }(), a.VersionDef = function () {\n    function e(e) {\n      if (this.badConsumers = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.producer = 0, e.prototype.minConsumer = 0, e.prototype.badConsumers = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.VersionDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.producer = e.int32();\n            break;\n\n          case 2:\n            r.minConsumer = e.int32();\n            break;\n\n          case 3:\n            if (r.badConsumers && r.badConsumers.length || (r.badConsumers = []), 2 == (7 & n)) for (var o = e.uint32() + e.pos; e.pos < o;) {\n              r.badConsumers.push(e.int32());\n            } else r.badConsumers.push(e.int32());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.GraphDef = function () {\n    function e(e) {\n      if (this.node = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.node = $util.emptyArray, e.prototype.versions = null, e.prototype.library = null, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.GraphDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.node && r.node.length || (r.node = []), r.node.push($root.tensorflow.NodeDef.decode(e, e.uint32()));\n            break;\n\n          case 4:\n            r.versions = $root.tensorflow.VersionDef.decode(e, e.uint32());\n            break;\n\n          case 2:\n            r.library = $root.tensorflow.FunctionDefLibrary.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.CollectionDef = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    var t;\n    return e.prototype.nodeList = null, e.prototype.bytesList = null, e.prototype.int64List = null, e.prototype.floatList = null, e.prototype.anyList = null, Object.defineProperty(e.prototype, \"kind\", {\n      get: $util.oneOfGetter(t = [\"nodeList\", \"bytesList\", \"int64List\", \"floatList\", \"anyList\"]),\n      set: $util.oneOfSetter(t)\n    }), e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.nodeList = $root.tensorflow.CollectionDef.NodeList.decode(e, e.uint32());\n            break;\n\n          case 2:\n            r.bytesList = $root.tensorflow.CollectionDef.BytesList.decode(e, e.uint32());\n            break;\n\n          case 3:\n            r.int64List = $root.tensorflow.CollectionDef.Int64List.decode(e, e.uint32());\n            break;\n\n          case 4:\n            r.floatList = $root.tensorflow.CollectionDef.FloatList.decode(e, e.uint32());\n            break;\n\n          case 5:\n            r.anyList = $root.tensorflow.CollectionDef.AnyList.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.NodeList = function () {\n      function e(e) {\n        if (this.value = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.value = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef.NodeList(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.value && r.value.length || (r.value = []), r.value.push(e.string());\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.BytesList = function () {\n      function e(e) {\n        if (this.value = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.value = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef.BytesList(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.value && r.value.length || (r.value = []), r.value.push(e.bytes());\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.Int64List = function () {\n      function e(e) {\n        if (this.value = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.value = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef.Int64List(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              if (r.value && r.value.length || (r.value = []), 2 == (7 & n)) for (var o = e.uint32() + e.pos; e.pos < o;) {\n                r.value.push(e.int64());\n              } else r.value.push(e.int64());\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.FloatList = function () {\n      function e(e) {\n        if (this.value = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.value = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef.FloatList(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              if (r.value && r.value.length || (r.value = []), 2 == (7 & n)) for (var o = e.uint32() + e.pos; e.pos < o;) {\n                r.value.push(e.float());\n              } else r.value.push(e.float());\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.AnyList = function () {\n      function e(e) {\n        if (this.value = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.value = $util.emptyArray, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.CollectionDef.AnyList(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.value && r.value.length || (r.value = []), r.value.push($root.tensorflow.Any.decode(e, e.uint32()));\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.SaverDef = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    var t, a;\n    return e.prototype.filenameTensorName = \"\", e.prototype.saveTensorName = \"\", e.prototype.restoreOpName = \"\", e.prototype.maxToKeep = 0, e.prototype.sharded = !1, e.prototype.keepCheckpointEveryNHours = 0, e.prototype.version = 0, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.SaverDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.filenameTensorName = e.string();\n            break;\n\n          case 2:\n            r.saveTensorName = e.string();\n            break;\n\n          case 3:\n            r.restoreOpName = e.string();\n            break;\n\n          case 4:\n            r.maxToKeep = e.int32();\n            break;\n\n          case 5:\n            r.sharded = e.bool();\n            break;\n\n          case 6:\n            r.keepCheckpointEveryNHours = e.float();\n            break;\n\n          case 7:\n            r.version = e.int32();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.CheckpointFormatVersion = (t = {}, (a = Object.create(t))[t[0] = \"LEGACY\"] = 0, a[t[1] = \"V1\"] = 1, a[t[2] = \"V2\"] = 2, a), e;\n  }(), a.TensorInfo = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    var t;\n    return e.prototype.name = \"\", e.prototype.cooSparse = null, e.prototype.dtype = 0, e.prototype.tensorShape = null, Object.defineProperty(e.prototype, \"encoding\", {\n      get: $util.oneOfGetter(t = [\"name\", \"cooSparse\"]),\n      set: $util.oneOfSetter(t)\n    }), e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.TensorInfo(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.name = e.string();\n            break;\n\n          case 4:\n            r.cooSparse = $root.tensorflow.TensorInfo.CooSparse.decode(e, e.uint32());\n            break;\n\n          case 2:\n            r.dtype = e.int32();\n            break;\n\n          case 3:\n            r.tensorShape = $root.tensorflow.TensorShape.decode(e, e.uint32());\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.CooSparse = function () {\n      function e(e) {\n        if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.valuesTensorName = \"\", e.prototype.indicesTensorName = \"\", e.prototype.denseShapeTensorName = \"\", e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.TensorInfo.CooSparse(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.valuesTensorName = e.string();\n              break;\n\n            case 2:\n              r.indicesTensorName = e.string();\n              break;\n\n            case 3:\n              r.denseShapeTensorName = e.string();\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.SignatureDef = function () {\n    function e(e) {\n      if (this.inputs = {}, this.outputs = {}, e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.inputs = $util.emptyObject, e.prototype.outputs = $util.emptyObject, e.prototype.methodName = \"\", e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a, r = void 0 === t ? e.len : e.pos + t, n = new $root.tensorflow.SignatureDef(); e.pos < r;) {\n        var o = e.uint32();\n\n        switch (o >>> 3) {\n          case 1:\n            e.skip().pos++, n.inputs === $util.emptyObject && (n.inputs = {}), a = e.string(), e.pos++, n.inputs[a] = $root.tensorflow.TensorInfo.decode(e, e.uint32());\n            break;\n\n          case 2:\n            e.skip().pos++, n.outputs === $util.emptyObject && (n.outputs = {}), a = e.string(), e.pos++, n.outputs[a] = $root.tensorflow.TensorInfo.decode(e, e.uint32());\n            break;\n\n          case 3:\n            n.methodName = e.string();\n            break;\n\n          default:\n            e.skipType(7 & o);\n        }\n      }\n\n      return n;\n    }, e;\n  }(), a.AssetFileDef = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.tensorInfo = null, e.prototype.filename = \"\", e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.AssetFileDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.tensorInfo = $root.tensorflow.TensorInfo.decode(e, e.uint32());\n            break;\n\n          case 2:\n            r.filename = e.string();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.OpDef = function () {\n    function e(e) {\n      if (this.inputArg = [], this.outputArg = [], this.attr = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.name = \"\", e.prototype.inputArg = $util.emptyArray, e.prototype.outputArg = $util.emptyArray, e.prototype.attr = $util.emptyArray, e.prototype.deprecation = null, e.prototype.summary = \"\", e.prototype.description = \"\", e.prototype.isCommutative = !1, e.prototype.isAggregate = !1, e.prototype.isStateful = !1, e.prototype.allowsUninitializedInput = !1, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.OpDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.name = e.string();\n            break;\n\n          case 2:\n            r.inputArg && r.inputArg.length || (r.inputArg = []), r.inputArg.push($root.tensorflow.OpDef.ArgDef.decode(e, e.uint32()));\n            break;\n\n          case 3:\n            r.outputArg && r.outputArg.length || (r.outputArg = []), r.outputArg.push($root.tensorflow.OpDef.ArgDef.decode(e, e.uint32()));\n            break;\n\n          case 4:\n            r.attr && r.attr.length || (r.attr = []), r.attr.push($root.tensorflow.OpDef.AttrDef.decode(e, e.uint32()));\n            break;\n\n          case 8:\n            r.deprecation = $root.tensorflow.OpDef.OpDeprecation.decode(e, e.uint32());\n            break;\n\n          case 5:\n            r.summary = e.string();\n            break;\n\n          case 6:\n            r.description = e.string();\n            break;\n\n          case 18:\n            r.isCommutative = e.bool();\n            break;\n\n          case 16:\n            r.isAggregate = e.bool();\n            break;\n\n          case 17:\n            r.isStateful = e.bool();\n            break;\n\n          case 19:\n            r.allowsUninitializedInput = e.bool();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e.ArgDef = function () {\n      function e(e) {\n        if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.name = \"\", e.prototype.description = \"\", e.prototype.type = 0, e.prototype.typeAttr = \"\", e.prototype.numberAttr = \"\", e.prototype.typeListAttr = \"\", e.prototype.isRef = !1, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.OpDef.ArgDef(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.name = e.string();\n              break;\n\n            case 2:\n              r.description = e.string();\n              break;\n\n            case 3:\n              r.type = e.int32();\n              break;\n\n            case 4:\n              r.typeAttr = e.string();\n              break;\n\n            case 5:\n              r.numberAttr = e.string();\n              break;\n\n            case 6:\n              r.typeListAttr = e.string();\n              break;\n\n            case 16:\n              r.isRef = e.bool();\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.AttrDef = function () {\n      function e(e) {\n        if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.name = \"\", e.prototype.type = \"\", e.prototype.defaultValue = null, e.prototype.description = \"\", e.prototype.hasMinimum = !1, e.prototype.minimum = $util.Long ? $util.Long.fromBits(0, 0, !1) : 0, e.prototype.allowedValues = null, e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.OpDef.AttrDef(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.name = e.string();\n              break;\n\n            case 2:\n              r.type = e.string();\n              break;\n\n            case 3:\n              r.defaultValue = $root.tensorflow.AttrValue.decode(e, e.uint32());\n              break;\n\n            case 4:\n              r.description = e.string();\n              break;\n\n            case 5:\n              r.hasMinimum = e.bool();\n              break;\n\n            case 6:\n              r.minimum = e.int64();\n              break;\n\n            case 7:\n              r.allowedValues = $root.tensorflow.AttrValue.decode(e, e.uint32());\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e.OpDeprecation = function () {\n      function e(e) {\n        if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.version = 0, e.prototype.explanation = \"\", e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.OpDef.OpDeprecation(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.version = e.int32();\n              break;\n\n            case 2:\n              r.explanation = e.string();\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.OpList = function () {\n    function e(e) {\n      if (this.op = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.op = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.OpList(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.op && r.op.length || (r.op = []), r.op.push($root.tensorflow.OpDef.decode(e, e.uint32()));\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.MetaGraphDef = function () {\n    function e(e) {\n      if (this.collectionDef = {}, this.signatureDef = {}, this.assetFileDef = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.metaInfoDef = null, e.prototype.graphDef = null, e.prototype.saverDef = null, e.prototype.collectionDef = $util.emptyObject, e.prototype.signatureDef = $util.emptyObject, e.prototype.assetFileDef = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a, r = void 0 === t ? e.len : e.pos + t, n = new $root.tensorflow.MetaGraphDef(); e.pos < r;) {\n        var o = e.uint32();\n\n        switch (o >>> 3) {\n          case 1:\n            n.metaInfoDef = $root.tensorflow.MetaGraphDef.MetaInfoDef.decode(e, e.uint32());\n            break;\n\n          case 2:\n            n.graphDef = $root.tensorflow.GraphDef.decode(e, e.uint32());\n            break;\n\n          case 3:\n            n.saverDef = $root.tensorflow.SaverDef.decode(e, e.uint32());\n            break;\n\n          case 4:\n            e.skip().pos++, n.collectionDef === $util.emptyObject && (n.collectionDef = {}), a = e.string(), e.pos++, n.collectionDef[a] = $root.tensorflow.CollectionDef.decode(e, e.uint32());\n            break;\n\n          case 5:\n            e.skip().pos++, n.signatureDef === $util.emptyObject && (n.signatureDef = {}), a = e.string(), e.pos++, n.signatureDef[a] = $root.tensorflow.SignatureDef.decode(e, e.uint32());\n            break;\n\n          case 6:\n            n.assetFileDef && n.assetFileDef.length || (n.assetFileDef = []), n.assetFileDef.push($root.tensorflow.AssetFileDef.decode(e, e.uint32()));\n            break;\n\n          default:\n            e.skipType(7 & o);\n        }\n      }\n\n      return n;\n    }, e.MetaInfoDef = function () {\n      function e(e) {\n        if (this.tags = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n          null != e[t[a]] && (this[t[a]] = e[t[a]]);\n        }\n      }\n\n      return e.prototype.metaGraphVersion = \"\", e.prototype.strippedOpList = null, e.prototype.anyInfo = null, e.prototype.tags = $util.emptyArray, e.prototype.tensorflowVersion = \"\", e.prototype.tensorflowGitVersion = \"\", e.decode = function (e, t) {\n        e instanceof $Reader || (e = $Reader.create(e));\n\n        for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.MetaGraphDef.MetaInfoDef(); e.pos < a;) {\n          var n = e.uint32();\n\n          switch (n >>> 3) {\n            case 1:\n              r.metaGraphVersion = e.string();\n              break;\n\n            case 2:\n              r.strippedOpList = $root.tensorflow.OpList.decode(e, e.uint32());\n              break;\n\n            case 3:\n              r.anyInfo = $root.tensorflow.Any.decode(e, e.uint32());\n              break;\n\n            case 4:\n              r.tags && r.tags.length || (r.tags = []), r.tags.push(e.string());\n              break;\n\n            case 5:\n              r.tensorflowVersion = e.string();\n              break;\n\n            case 6:\n              r.tensorflowGitVersion = e.string();\n              break;\n\n            default:\n              e.skipType(7 & n);\n          }\n        }\n\n        return r;\n      }, e;\n    }(), e;\n  }(), a.SavedModel = function () {\n    function e(e) {\n      if (this.metaGraphs = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.savedModelSchemaVersion = $util.Long ? $util.Long.fromBits(0, 0, !1) : 0, e.prototype.metaGraphs = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.SavedModel(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.savedModelSchemaVersion = e.int64();\n            break;\n\n          case 2:\n            r.metaGraphs && r.metaGraphs.length || (r.metaGraphs = []), r.metaGraphs.push($root.tensorflow.MetaGraphDef.decode(e, e.uint32()));\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.FunctionDefLibrary = function () {\n    function e(e) {\n      if (this.function = [], this.gradient = [], e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.function = $util.emptyArray, e.prototype.gradient = $util.emptyArray, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.FunctionDefLibrary(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.function && r.function.length || (r.function = []), r.function.push($root.tensorflow.FunctionDef.decode(e, e.uint32()));\n            break;\n\n          case 2:\n            r.gradient && r.gradient.length || (r.gradient = []), r.gradient.push($root.tensorflow.GradientDef.decode(e, e.uint32()));\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a.FunctionDef = function () {\n    function e(e) {\n      if (this.attr = {}, this.nodeDef = [], this.ret = {}, e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.signature = null, e.prototype.attr = $util.emptyObject, e.prototype.nodeDef = $util.emptyArray, e.prototype.ret = $util.emptyObject, e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a, r = void 0 === t ? e.len : e.pos + t, n = new $root.tensorflow.FunctionDef(); e.pos < r;) {\n        var o = e.uint32();\n\n        switch (o >>> 3) {\n          case 1:\n            n.signature = $root.tensorflow.OpDef.decode(e, e.uint32());\n            break;\n\n          case 5:\n            e.skip().pos++, n.attr === $util.emptyObject && (n.attr = {}), a = e.string(), e.pos++, n.attr[a] = $root.tensorflow.AttrValue.decode(e, e.uint32());\n            break;\n\n          case 3:\n            n.nodeDef && n.nodeDef.length || (n.nodeDef = []), n.nodeDef.push($root.tensorflow.NodeDef.decode(e, e.uint32()));\n            break;\n\n          case 4:\n            e.skip().pos++, n.ret === $util.emptyObject && (n.ret = {}), a = e.string(), e.pos++, n.ret[a] = e.string();\n            break;\n\n          default:\n            e.skipType(7 & o);\n        }\n      }\n\n      return n;\n    }, e;\n  }(), a.GradientDef = function () {\n    function e(e) {\n      if (e) for (var t = Object.keys(e), a = 0; a < t.length; ++a) {\n        null != e[t[a]] && (this[t[a]] = e[t[a]]);\n      }\n    }\n\n    return e.prototype.functionName = \"\", e.prototype.gradientFunc = \"\", e.decode = function (e, t) {\n      e instanceof $Reader || (e = $Reader.create(e));\n\n      for (var a = void 0 === t ? e.len : e.pos + t, r = new $root.tensorflow.GradientDef(); e.pos < a;) {\n        var n = e.uint32();\n\n        switch (n >>> 3) {\n          case 1:\n            r.functionName = e.string();\n            break;\n\n          case 2:\n            r.gradientFunc = e.string();\n            break;\n\n          default:\n            e.skipType(7 & n);\n        }\n      }\n\n      return r;\n    }, e;\n  }(), a;\n}();\n\nvar compiled_api = $root,\n    compiled_api_1 = compiled_api.tensorflow;\n\nfunction getParamValue(e, t, a, r) {\n  var n = t.params[e];\n\n  if (n && void 0 !== n.inputIndex) {\n    if (\"tensor\" === n.type) return getTensor(t.inputNames[n.inputIndex], a, r);\n    if (\"tensors\" === n.type) return (0 === n.inputIndex ? 0 === n.inputParamLength ? t.inputNames : t.inputNames.slice(n.inputIndex, -n.inputParamLength) : t.inputNames.splice(n.inputIndex)).map(function (e) {\n      return getTensor(e, a, r);\n    });\n    var o = Array.prototype.slice.call(getTensor(t.inputNames.slice(n.inputIndex)[0], a, r).dataSync());\n    return \"number\" === n.type ? o[0] : o;\n  }\n\n  return n && n.value;\n}\n\nfunction getTensor(e, t, a) {\n  var r = parseNodeName(e),\n      n = r[0],\n      o = r[1],\n      s = a.currentContextIds.find(function (e) {\n    return !!t[getNodeNameWithContextId(n, e)];\n  });\n  return void 0 !== s ? t[getNodeNameWithContextId(n, s)][o] : void 0;\n}\n\nfunction getTensorsForCurrentContenxt(e, t, a) {\n  return t[getNodeNameWithContextId(e, a.currentContextId)];\n}\n\nfunction getNodeNameAndIndex(e, t) {\n  var a = parseNodeName(e),\n      r = a[0],\n      n = a[1];\n  return [getNodeNameWithContextId(r, t && t.currentContextId), n];\n}\n\nfunction getNodeNameWithContextId(e, t) {\n  return t ? e + \"-\" + t : e;\n}\n\nfunction parseNodeName(e) {\n  var t = e.lastIndexOf(\":\");\n  return -1 === t ? [e, 0] : [e.substring(0, t), Number(e.substring(t + 1))];\n}\n\nfunction split$1(e, t) {\n  for (var a = [], r = 0; r < e.length; r += t) {\n    a.push(e.slice(r, r + t));\n  }\n\n  return a;\n}\n\nvar json = [{\n  tfOpName: \"Add\",\n  dlOpName: \"add\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AddN\",\n  dlOpName: \"addN\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 0,\n    dlParamName: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"BiasAdd\",\n  dlOpName: \"add\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sub\",\n  dlOpName: \"sub\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"RealDiv\",\n  dlOpName: \"div\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Div\",\n  dlOpName: \"div\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorDiv\",\n  dlOpName: \"floorDiv\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mul\",\n  dlOpName: \"mul\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Maximum\",\n  dlOpName: \"maximum\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Minimum\",\n  dlOpName: \"minimum\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Pow\",\n  dlOpName: \"pow\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"SquaredDifference\",\n  dlOpName: \"squaredDifference\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mod\",\n  dlOpName: \"mod\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorMod\",\n  dlOpName: \"mod\",\n  category: \"arithmetic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    arithmetic = Object.freeze({\n  json: json\n}),\n    json$1 = [{\n  tfOpName: \"Abs\",\n  dlOpName: \"abs\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acos\",\n  dlOpName: \"acos\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asin\",\n  dlOpName: \"asin\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan\",\n  dlOpName: \"atan\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan2\",\n  dlOpName: \"atan2\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"y\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ceil\",\n  dlOpName: \"ceil\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ClipByValue\",\n  dlOpName: \"clipByValue\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"clip_value_min\",\n    dlParamName: \"clipValueMin\",\n    type: \"number\"\n  }, {\n    tfParamName: \"clip_value_max\",\n    dlParamName: \"clipValueMax\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Cos\",\n  dlOpName: \"cos\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Cosh\",\n  dlOpName: \"cosh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Elu\",\n  dlOpName: \"elu\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Exp\",\n  dlOpName: \"exp\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Floor\",\n  dlOpName: \"floor\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log\",\n  dlOpName: \"log\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Neg\",\n  dlOpName: \"neg\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu\",\n  dlOpName: \"relu\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu6\",\n  dlOpName: \"clipByValue\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    dlParamName: \"clipValueMin\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    dlParamName: \"clipValueMax\",\n    type: \"number\",\n    defaultValue: 6\n  }]\n}, {\n  tfOpName: \"Selu\",\n  dlOpName: \"selu\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sigmoid\",\n  dlOpName: \"sigmoid\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sin\",\n  dlOpName: \"sin\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sinh\",\n  dlOpName: \"sinh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sqrt\",\n  dlOpName: \"sqrt\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Rsqrt\",\n  dlOpName: \"rsqrt\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Square\",\n  dlOpName: \"square\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tan\",\n  dlOpName: \"tan\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tanh\",\n  dlOpName: \"tanh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sign\",\n  dlOpName: \"sign\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Round\",\n  dlOpName: \"round\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Expm1\",\n  dlOpName: \"expm1\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log1p\",\n  dlOpName: \"log1p\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reciprocal\",\n  dlOpName: \"reciprocal\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reciprocal\",\n  dlOpName: \"reciprocal\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Softplus\",\n  dlOpName: \"softplus\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asinh\",\n  dlOpName: \"asinh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acosh\",\n  dlOpName: \"acosh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atanh\",\n  dlOpName: \"atanh\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Erf\",\n  dlOpName: \"erf\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Prod\",\n  dlOpName: \"prod\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axes\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\",\n    notSupported: !0\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LeakyRelu\",\n  dlOpName: \"leakyRelu\",\n  category: \"basic_math\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"alpha\",\n    dlParamName: \"alpha\",\n    type: \"number\",\n    defaultValue: .2\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    basicMath = Object.freeze({\n  json: json$1\n}),\n    json$2 = [{\n  tfOpName: \"LoopCond\",\n  dlOpName: \"loopCond\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Switch\",\n  dlOpName: \"switch\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"data\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Merge\",\n  dlOpName: \"merge\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 0,\n    dlParamName: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Enter\",\n  dlOpName: \"enter\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfParamName: \"frame_name\",\n    dlParamName: \"frameName\",\n    type: \"string\"\n  }, {\n    tfParamName: \"is_constant\",\n    dlParamName: \"isConstant\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Exit\",\n  dlOpName: \"exit\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NextIteration\",\n  dlOpName: \"nextIteration\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayV3\",\n  dlOpName: \"tensorArray\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"size\",\n    type: \"number\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfParamName: \"element_shape\",\n    dlParamName: \"elementShape\",\n    type: \"shape\"\n  }, {\n    tfParamName: \"dynamic_size\",\n    dlParamName: \"dynamicSize\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"clear_after_read\",\n    dlParamName: \"clearAfterRead\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"identical_element_shapes\",\n    dlParamName: \"identicalElementShapes\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"tensor_array_name\",\n    dlParamName: \"name\",\n    type: \"string\"\n  }]\n}, {\n  tfOpName: \"TensorArrayWriteV3\",\n  dlOpName: \"tensorArrayWrite\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"index\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayReadV3\",\n  dlOpName: \"tensorArrayRead\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"index\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayGatherV3\",\n  dlOpName: \"tensorArrayGather\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"indices\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfParamName: \"element_shape\",\n    dlParamName: \"elementShape\",\n    type: \"shape\"\n  }]\n}, {\n  tfOpName: \"TensorArrayScatterV3\",\n  dlOpName: \"tensorArrayScatter\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"indices\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArrayConcatV3\",\n  dlOpName: \"tensorArrayConcat\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfParamName: \"element_shape_except0\",\n    dlParamName: \"elementShapeExcept0\",\n    type: \"shape\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArraySplitV3\",\n  dlOpName: \"tensorArraySplit\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"lengths\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArraySizeV3\",\n  dlOpName: \"tensorArraySize\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"flowIn\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"TensorArrayCloseV3\",\n  dlOpName: \"tensorArrayClose\",\n  category: \"control\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"tensorArrayId\",\n    type: \"number\"\n  }]\n}],\n    control = Object.freeze({\n  json: json$2\n}),\n    json$3 = [{\n  tfOpName: \"AvgPool\",\n  dlOpName: \"avgPool\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfParamName: \"ksize\",\n    dlParamName: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPool\",\n  dlOpName: \"maxPool\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfParamName: \"ksize\",\n    dlParamName: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Conv1D\",\n  dlOpName: \"conv1d\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"filter\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"stride\",\n    dlParamName: \"stride\",\n    type: \"number\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NWC\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfParamName: \"dilation\",\n    dlParamName: \"dilation\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"Conv2D\",\n  dlOpName: \"conv2d\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"filter\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"useCudnnOnGpu\",\n    dlParamName: \"useCudnnOnGpu\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfParamName: \"dilations\",\n    dlParamName: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Conv2DBackpropInput\",\n  dlOpName: \"conv2dTranspose\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 2,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"filter\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 0,\n    dlParamName: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2d\",\n  dlOpName: \"depthwiseConv2d\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"input\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"filter\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfParamName: \"dilations\",\n    dlParamName: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2dNative\",\n  dlOpName: \"depthwiseConv2d\",\n  category: \"convolution\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"input\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"filter\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"strides\",\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"padding\",\n    dlParamName: \"pad\",\n    type: \"string\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfParamName: \"dilations\",\n    dlParamName: \"dilations\",\n    type: \"number[]\"\n  }]\n}],\n    convolution = Object.freeze({\n  json: json$3\n}),\n    json$4 = [{\n  tfOpName: \"Fill\",\n  dlOpName: \"fill\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"value\",\n    type: \"number\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"LinSpace\",\n  dlOpName: \"linspace\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"start\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"stop\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"num\",\n    type: \"number\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"OneHot\",\n  dlOpName: \"oneHot\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"indices\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"depth\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"onValue\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"offValue\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"axis\",\n    dlParamName: \"axis\",\n    type: \"number\",\n    notSupported: !0\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ones\",\n  dlOpName: \"ones\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"OnesLike\",\n  dlOpName: \"onesLike\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"RandomUniform\",\n  dlOpName: \"randomUniform\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"minval\",\n    dlParamName: \"minval\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"maxval\",\n    dlParamName: \"maxval\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfParamName: \"seed\",\n    dlParamName: \"seed\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"seed2\",\n    dlParamName: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Range\",\n  dlOpName: \"range\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"start\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"stop\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"step\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"Tidx\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"truncatedNormal\",\n  dlOpName: \"truncatedNormal\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"means\",\n    dlParamName: \"mean\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"stddev\",\n    dlParamName: \"stdDev\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfParamName: \"seed\",\n    dlParamName: \"seed\",\n    type: \"number\"\n  }, {\n    tfParamName: \"seed2\",\n    dlParamName: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Zeros\",\n  dlOpName: \"zeros\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ZerosLike\",\n  dlOpName: \"zerosLike\",\n  category: \"creation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}],\n    creation = Object.freeze({\n  json: json$4\n}),\n    json$5 = [{\n  tfOpName: \"NonMaxSuppressionV2\",\n  dlOpName: \"nonMaxSuppression\",\n  category: \"dynamic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"boxes\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"scores\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"iouThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"NonMaxSuppressionV3\",\n  dlOpName: \"nonMaxSuppression\",\n  category: \"dynamic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"boxes\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"scores\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"iouThreshold\",\n    type: \"number\"\n  }, {\n    tfInputIndex: 4,\n    dlParamName: \"scoreThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Where\",\n  dlOpName: \"whereAsync\",\n  category: \"dynamic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"condition\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ListDiff\",\n  dlOpName: \"setdiff1dAsync\",\n  category: \"dynamic\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"y\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    dynamic = Object.freeze({\n  json: json$5\n}),\n    json$6 = [{\n  tfOpName: \"TopKV2\",\n  dlOpName: \"topK\",\n  category: \"evaluation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"k\",\n    type: \"number\"\n  }, {\n    tfParamName: \"sorted\",\n    dlParamName: \"sorted\",\n    type: \"bool\"\n  }]\n}],\n    evaluation = Object.freeze({\n  json: json$6\n}),\n    json$7 = [{\n  tfOpName: \"PlaceholderWithDefault\",\n  dlOpName: \"placeholder\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"default\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"shape\",\n    dlParamName: \"shape\",\n    type: \"shape\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Placeholder\",\n  dlOpName: \"placeholder\",\n  category: \"graph\",\n  params: [{\n    tfParamName: \"shape\",\n    dlParamName: \"shape\",\n    type: \"shape\"\n  }, {\n    tfParamName: \"dtype\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Const\",\n  dlOpName: \"const\",\n  category: \"graph\"\n}, {\n  tfOpName: \"Identity\",\n  dlOpName: \"identity\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Snapshot\",\n  dlOpName: \"snapshot\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Rank\",\n  dlOpName: \"rank\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Size\",\n  dlOpName: \"size\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Shape\",\n  dlOpName: \"shape\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"ShapeN\",\n  dlOpName: \"shapeN\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 0,\n    dlParamName: \"x\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Print\",\n  dlOpName: \"print\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    tfInputParamLength: 1,\n    dlParamName: \"data\",\n    type: \"tensors\"\n  }, {\n    tfParamName: \"message\",\n    dlParamName: \"message\",\n    type: \"string\"\n  }, {\n    tfParamName: \"first_n\",\n    dlParamName: \"firstN\",\n    type: \"number\",\n    notSupprted: !0\n  }, {\n    tfParamName: \"summarize\",\n    dlParamName: \"summarize\",\n    type: \"number\",\n    defaultValue: 3\n  }]\n}, {\n  tfOpName: \"NoOp\",\n  dlOpName: \"noop\",\n  category: \"graph\",\n  params: []\n}, {\n  tfOpName: \"StopGradient\",\n  dlOpName: \"stopGradient\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"FakeQuantWithMinMaxVars\",\n  dlOpName: \"fakeQuantWithMinMaxVars\",\n  category: \"graph\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"min\",\n    dlParamName: \"min\",\n    type: \"number\"\n  }, {\n    tfParamName: \"max\",\n    dlParamName: \"max\",\n    type: \"number\"\n  }]\n}],\n    graph = Object.freeze({\n  json: json$7\n}),\n    json$8 = [{\n  tfOpName: \"ResizeBilinear\",\n  dlOpName: \"resizeBilinear\",\n  category: \"image\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"images\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"size\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"align_corners\",\n    dlParamName: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ResizeNearestNeighbor\",\n  dlOpName: \"resizeNearestNeighbor\",\n  category: \"image\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"images\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"size\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"align_corners\",\n    dlParamName: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"CropAndResize\",\n  dlOpName: \"cropAndResize\",\n  category: \"image\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"image\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"boxes\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"boxInd\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"cropSize\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"method\",\n    dlParamName: \"method\",\n    type: \"string\"\n  }, {\n    tfParamName: \"extrapolation_value\",\n    dlParamName: \"extrapolationValue\",\n    type: \"number\"\n  }]\n}],\n    image$1 = Object.freeze({\n  json: json$8\n}),\n    json$9 = [{\n  tfOpName: \"Equal\",\n  dlOpName: \"equal\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NotEqual\",\n  dlOpName: \"notEqual\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Greater\",\n  dlOpName: \"greater\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"GreaterEqual\",\n  dlOpName: \"greaterEqual\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Less\",\n  dlOpName: \"less\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LessEqual\",\n  dlOpName: \"lessEqual\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalAnd\",\n  dlOpName: \"logicalAnd\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalNot\",\n  dlOpName: \"logicalNot\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalOr\",\n  dlOpName: \"logicalOr\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Select\",\n  dlOpName: \"where\",\n  category: \"logical\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"condition\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    logical = Object.freeze({\n  json: json$9\n}),\n    json$10 = [{\n  tfOpName: \"MatMul\",\n  dlOpName: \"matMul\",\n  category: \"matrices\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"transpose_a\",\n    dlParamName: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfParamName: \"transpose_b\",\n    dlParamName: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"BatchMatMul\",\n  dlOpName: \"matMul\",\n  category: \"matrices\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"a\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"b\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"adj_x\",\n    dlParamName: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfParamName: \"adj_y\",\n    dlParamName: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Transpose\",\n  dlOpName: \"transpose\",\n  category: \"matrices\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"perm\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"T\",\n    dlParamName: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    matrices = Object.freeze({\n  json: json$10\n}),\n    json$11 = [{\n  tfOpName: \"FusedBatchNorm\",\n  dlOpName: \"batchNormalization\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"scale\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"offset\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"mean\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 4,\n    dlParamName: \"variance\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"epsilon\",\n    dlParamName: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FusedBatchNormV2\",\n  dlOpName: \"batchNormalization\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"scale\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"offset\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"mean\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 4,\n    dlParamName: \"variance\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"epsilon\",\n    dlParamName: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LRN\",\n  dlOpName: \"localResponseNormalization\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"depth_radius\",\n    dlParamName: \"radius\",\n    type: \"number\",\n    defaultValue: 5\n  }, {\n    tfParamName: \"bias\",\n    dlParamName: \"bias\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfParamName: \"alpha\",\n    dlParamName: \"alpha\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfParamName: \"beta\",\n    dlParamName: \"beta\",\n    type: \"number\",\n    defaultValue: .5\n  }]\n}, {\n  tfOpName: \"Softmax\",\n  dlOpName: \"softmax\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"LogSoftmax\",\n  dlOpName: \"logSoftmax\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  dlOpName: \"sparseToDense\",\n  category: \"normalization\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"defaultValue\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"validate_indices\",\n    dlParamName: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !0,\n    notSupported: !0\n  }]\n}],\n    normalization = Object.freeze({\n  json: json$11\n}),\n    json$12 = [{\n  tfOpName: \"Max\",\n  dlOpName: \"max\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Mean\",\n  dlOpName: \"mean\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Min\",\n  dlOpName: \"min\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Sum\",\n  dlOpName: \"sum\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"All\",\n  dlOpName: \"all\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Any\",\n  dlOpName: \"any\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"ArgMax\",\n  dlOpName: \"argMax\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"ArgMin\",\n  dlOpName: \"argMin\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Prod\",\n  dlOpName: \"prod\",\n  category: \"reduction\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"keep_dims\",\n    dlParamName: \"keepDims\",\n    type: \"bool\"\n  }]\n}],\n    reduction = Object.freeze({\n  json: json$12\n}),\n    json$13 = [{\n  tfOpName: \"ConcatV2\",\n  dlOpName: \"concat\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 1,\n    dlParamName: \"tensors\",\n    type: \"tensors\"\n  }, {\n    tfInputIndex: -1,\n    dlParamName: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Concat\",\n  dlOpName: \"concat\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 1,\n    tfInputParamLength: 1,\n    dlParamName: \"tensors\",\n    type: \"tensors\"\n  }, {\n    tfInputIndex: 0,\n    dlParamName: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"GatherV2\",\n  dlOpName: \"gather\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"indices\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Gather\",\n  dlOpName: \"gather\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"indices\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"axis\",\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"validate_indices\",\n    dlParamName: \"validateIndices\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reverse\",\n  dlOpName: \"reverse\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"dims\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ReverseV2\",\n  dlOpName: \"reverse\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Slice\",\n  dlOpName: \"slice\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"begin\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"size\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"StridedSlice\",\n  dlOpName: \"stridedSlice\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"begin\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"end\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"begin_mask\",\n    dlParamName: \"beginMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"end_mask\",\n    dlParamName: \"endMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"new_axis_mask\",\n    dlParamName: \"newAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"ellipsis_mask\",\n    dlParamName: \"ellipsisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"shrink_axis_mask\",\n    dlParamName: \"shrinkAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Pack\",\n  dlOpName: \"stack\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 0,\n    dlParamName: \"tensors\",\n    type: \"tensors\"\n  }, {\n    tfParamName: \"axis\",\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Unpack\",\n  dlOpName: \"unstack\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    tfInputParamLength: 0,\n    dlParamName: \"tensor\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"axis\",\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfParamName: \"num\",\n    dlParamName: \"num\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tile\",\n  dlOpName: \"tile\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"reps\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Split\",\n  dlOpName: \"split\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"num_split\",\n    dlParamName: \"numOrSizeSplits\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"SplitV\",\n  dlOpName: \"split\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"numOrSizeSplits\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"ScatterNd\",\n  dlOpName: \"scatterNd\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"indices\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"values\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"GatherNd\",\n  dlOpName: \"gatherNd\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"indices\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  dlOpName: \"sparseToDense\",\n  category: \"slice_join\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 3,\n    dlParamName: \"defaultValue\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"validate_indices\",\n    dlParamName: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !1,\n    notSupported: !0\n  }]\n}],\n    sliceJoin = Object.freeze({\n  json: json$13\n}),\n    json$14 = [{\n  tfOpName: \"FFT\",\n  dlOpName: \"fft\",\n  category: \"spectral\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"IFFT\",\n  dlOpName: \"ifft\",\n  category: \"spectral\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"RFFT\",\n  dlOpName: \"rfft\",\n  category: \"spectral\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"fft_length\",\n    type: \"number\",\n    unsupported: !0\n  }]\n}, {\n  tfOpName: \"IRFFT\",\n  dlOpName: \"irfft\",\n  category: \"spectral\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"fft_length\",\n    type: \"number\",\n    unsupported: !0\n  }]\n}],\n    spectral = Object.freeze({\n  json: json$14\n}),\n    json$15 = [{\n  tfOpName: \"Cast\",\n  dlOpName: \"cast\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"SrcT\",\n    dlParamName: \"sdtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfParamName: \"DstT\",\n    dlParamName: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ExpandDims\",\n  dlOpName: \"expandDims\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    tfParamNameDeprecated: \"dim\",\n    dlParamName: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Pad\",\n  dlOpName: \"pad\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"padding\",\n    type: \"number[]\"\n  }, {\n    tfParamName: \"constant_value\",\n    dlParamName: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"PadV2\",\n  dlOpName: \"pad\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"padding\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Reshape\",\n  dlOpName: \"reshape\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Squeeze\",\n  dlOpName: \"squeeze\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"axis\",\n    tfParamNameDeprecated: \"squeeze_dims\",\n    dlParamName: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"SpaceToBatchND\",\n  dlOpName: \"spaceToBatchND\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"paddings\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"BatchToSpaceND\",\n  dlOpName: \"batchToSpaceND\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfInputIndex: 1,\n    dlParamName: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    tfInputIndex: 2,\n    dlParamName: \"crops\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthToSpace\",\n  dlOpName: \"depthToSpace\",\n  category: \"transformation\",\n  params: [{\n    tfInputIndex: 0,\n    dlParamName: \"x\",\n    type: \"tensor\"\n  }, {\n    tfParamName: \"block_size\",\n    dlParamName: \"blockSize\",\n    type: \"number\"\n  }, {\n    tfParamName: \"data_format\",\n    dlParamName: \"dataFormat\",\n    type: \"string\"\n  }]\n}],\n    transformation = Object.freeze({\n  json: json$15\n}),\n    CONTROL_FLOW_OPS = [\"Switch\", \"Merge\", \"Enter\", \"Exit\", \"NextIteration\"],\n    DYNAMIC_SHAPE_OPS = [\"NonMaxSuppressionV2\", \"NonMaxSuppressionV3\", \"Where\"],\n    OperationMapper = function () {\n  function e() {\n    var e = [arithmetic, basicMath, control, convolution, creation, dynamic, evaluation, logical, image$1, graph, matrices, normalization, reduction, sliceJoin, spectral, transformation],\n        t = [].concat.apply([], e.map(function (e) {\n      return e.json;\n    }));\n    this.opMappers = t.reduce(function (e, t) {\n      return e[t.tfOpName] = t, e;\n    }, {});\n  }\n\n  return Object.defineProperty(e, \"Instance\", {\n    get: function get() {\n      return this._instance || (this._instance = new this());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.isControlFlow = function (e) {\n    return CONTROL_FLOW_OPS.some(function (t) {\n      return t === e.op;\n    });\n  }, e.prototype.isDynamicShape = function (e) {\n    return DYNAMIC_SHAPE_OPS.some(function (t) {\n      return t === e.op;\n    });\n  }, e.prototype.transformGraph = function (e) {\n    var t = this,\n        a = !1,\n        r = !1,\n        n = [],\n        o = [],\n        s = e.node.reduce(function (e, s) {\n      return e[s.name] = t.mapNode(s), t.isControlFlow(s) && (a = !0), t.isDynamicShape(s) && (r = !0), \"Placeholder\" === s.op && n.push(e[s.name]), \"Const\" === s.op && o.push(e[s.name]), e;\n    }, {}),\n        i = [],\n        p = [];\n    return Object.keys(s).forEach(function (e) {\n      var t = s[e];\n      t.inputNames.forEach(function (e) {\n        var a = getNodeNameAndIndex(e)[0];\n        t.inputs.push(s[a]), s[a].children.push(t);\n      }), 0 === t.inputs.length && i.push(t);\n    }), Object.keys(s).forEach(function (e) {\n      var t = s[e];\n      0 === t.children.length && p.push(t);\n    }), {\n      nodes: s,\n      inputs: i,\n      outputs: p,\n      weights: o,\n      placeholders: n,\n      withControlFlow: a,\n      withDynamicShape: r\n    };\n  }, e.prototype.mapNode = function (e) {\n    var t = this,\n        a = this.opMappers[e.op];\n    if (void 0 === a) throw new Error(\"Tensorflow Op is not supported: \" + e.op);\n    var r = {\n      name: e.name,\n      op: a.dlOpName,\n      category: a.category,\n      inputNames: (e.input || []).map(function (e) {\n        return e.startsWith(\"^\") ? e.substr(1) : e;\n      }),\n      inputs: [],\n      children: [],\n      params: {}\n    };\n    return a.params && (r.params = a.params.reduce(function (a, r) {\n      var n = r.tfInputIndex,\n          o = r.tfInputParamLength,\n          s = r.type,\n          i = void 0;\n      if (void 0 === n) switch (r.type) {\n        case \"string\":\n          void 0 === (i = t.getStringParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getStringParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"number\":\n          void 0 === (i = t.getNumberParam(e.attr, r.tfParamName, r.defaultValue || 0)) && r.tfParamNameDeprecated && (i = t.getNumberParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"number[]\":\n          void 0 === (i = t.getNumericArrayParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getNumericArrayParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"bool\":\n          void 0 === (i = t.getBoolParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getBoolParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"shape\":\n          void 0 === (i = t.getTensorShapeParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getTensorShapeParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"dtype\":\n          void 0 === (i = t.getDtypeParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getDtypeParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"tensor\":\n        case \"tensors\":\n          break;\n\n        default:\n          throw new Error(\"Unsupported param type: \" + r.type + \" for op: \" + e.op);\n      }\n      return a[r.dlParamName] = {\n        value: i,\n        inputIndex: n,\n        type: s,\n        inputParamLength: o\n      }, a;\n    }, {})), r;\n  }, e.prototype.getStringParam = function (e, t, a, r) {\n    void 0 === r && (r = !1);\n    var n = e[t];\n\n    if (void 0 !== n) {\n      var o = String.fromCharCode.apply(null, n.s);\n      return r ? o : o.toLowerCase();\n    }\n\n    return a;\n  }, e.prototype.getBoolParam = function (e, t, a) {\n    var r = e[t];\n    return r ? r.b : a;\n  }, e.prototype.getNumberParam = function (e, t, a) {\n    var r = e[t],\n        n = r ? r[r.value] : a;\n    return \"number\" == typeof n ? n : n.toInt();\n  }, e.prototype.getDtypeParam = function (e, t, a) {\n    var r = e[t];\n    if (r && r.type) switch (r.type) {\n      case compiled_api_1.DataType.DT_FLOAT:\n        return \"float32\";\n\n      case compiled_api_1.DataType.DT_INT32:\n        return \"int32\";\n\n      case compiled_api_1.DataType.DT_BOOL:\n        return \"bool\";\n\n      default:\n        return a;\n    }\n    return a;\n  }, e.prototype.getTensorShapeParam = function (e, t, a) {\n    var r = e[t];\n    return r && r.shape ? r.shape.dim.map(function (e) {\n      return \"number\" == typeof e.size ? e.size : e.size.toInt();\n    }) : a;\n  }, e.prototype.getNumericArrayParam = function (e, t, a) {\n    var r = e[t];\n    return r ? (r.list.f && r.list.f.length ? r.list.f : r.list.i).map(function (e) {\n      return \"number\" == typeof e ? e : e.toInt();\n    }) : a;\n  }, e;\n}(),\n    executeOp = function executeOp(e, t, a) {\n  switch (e.op) {\n    case \"add\":\n      return [add(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"addN\":\n      return [addN(getParamValue(\"tensors\", e, t, a))];\n\n    case \"mod\":\n      return [mod(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"mul\":\n      return [mul(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"div\":\n      return [div(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"floorDiv\":\n      return [floorDiv(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"sub\":\n      return [sub(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"minimum\":\n      return [minimum(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"maximum\":\n      return [maximum(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"pow\":\n      return [pow(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"squaredDifference\":\n      return [squaredDifference(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$1 = function executeOp$1(e, t, a) {\n  switch (e.op) {\n    case \"abs\":\n      return [abs(getParamValue(\"x\", e, t, a))];\n\n    case \"acos\":\n      return [acos(getParamValue(\"x\", e, t, a))];\n\n    case \"acosh\":\n      return [acosh(getParamValue(\"x\", e, t, a))];\n\n    case \"asin\":\n      return [asin(getParamValue(\"x\", e, t, a))];\n\n    case \"asinh\":\n      return [asinh(getParamValue(\"x\", e, t, a))];\n\n    case \"atan\":\n      return [atan(getParamValue(\"x\", e, t, a))];\n\n    case \"atan2\":\n      return [atan2(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n    case \"atanh\":\n      return [atanh(getParamValue(\"x\", e, t, a))];\n\n    case \"ceil\":\n      return [ceil(getParamValue(\"x\", e, t, a))];\n\n    case \"cos\":\n      return [cos(getParamValue(\"x\", e, t, a))];\n\n    case \"cosh\":\n      return [cosh(getParamValue(\"x\", e, t, a))];\n\n    case \"elu\":\n      return [elu(getParamValue(\"x\", e, t, a))];\n\n    case \"erf\":\n      return [erf(getParamValue(\"x\", e, t, a))];\n\n    case \"exp\":\n      return [exp(getParamValue(\"x\", e, t, a))];\n\n    case \"expm1\":\n      return [expm1(getParamValue(\"x\", e, t, a))];\n\n    case \"floor\":\n      return [floor(getParamValue(\"x\", e, t, a))];\n\n    case \"log\":\n      return [log(getParamValue(\"x\", e, t, a))];\n\n    case \"log1p\":\n      return [log1p(getParamValue(\"x\", e, t, a))];\n\n    case \"neg\":\n      return [neg(getParamValue(\"x\", e, t, a))];\n\n    case \"reciprocal\":\n      return [reciprocal(getParamValue(\"x\", e, t, a))];\n\n    case \"relu\":\n      return [relu(getParamValue(\"x\", e, t, a))];\n\n    case \"round\":\n      return [round(getParamValue(\"x\", e, t, a))];\n\n    case \"selu\":\n      return [selu(getParamValue(\"x\", e, t, a))];\n\n    case \"sigmoid\":\n      return [sigmoid(getParamValue(\"x\", e, t, a))];\n\n    case \"sin\":\n      return [sin(getParamValue(\"x\", e, t, a))];\n\n    case \"sign\":\n      return [sign(getParamValue(\"x\", e, t, a))];\n\n    case \"sinh\":\n      return [sinh(getParamValue(\"x\", e, t, a))];\n\n    case \"softplus\":\n      return [softplus(getParamValue(\"x\", e, t, a))];\n\n    case \"sqrt\":\n      return [sqrt(getParamValue(\"x\", e, t, a))];\n\n    case \"square\":\n      return [square(getParamValue(\"x\", e, t, a))];\n\n    case \"tanh\":\n      return [tanh(getParamValue(\"x\", e, t, a))];\n\n    case \"tan\":\n      return [tan(getParamValue(\"x\", e, t, a))];\n\n    case \"clipByValue\":\n      return [clipByValue(getParamValue(\"x\", e, t, a), getParamValue(\"clipValueMin\", e, t, a), getParamValue(\"clipValueMax\", e, t, a))];\n\n    case \"rsqrt\":\n      return [div(scalar(1, \"float32\"), sqrt(getTensor(e.inputNames[0], t, a)))];\n\n    case \"prod\":\n      return [prod(getParamValue(\"x\", e, t, a), getParamValue(\"axes\", e, t, a))];\n\n    case \"leakyRelu\":\n      return [leakyRelu(getParamValue(\"x\", e, t, a), getParamValue(\"alpha\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    TensorArray = function () {\n  function e(t, a, r, n, o, s, i) {\n    this.name = t, this.dtype = a, this.maxSize = r, this.elementShape = n, this.identicalElementShapes = o, this.dynamicSize = s, this.clearAfterRead = i, this.tensors = [], this.closed_ = !1, this.id = e.nextId++;\n  }\n\n  return Object.defineProperty(e.prototype, \"closed\", {\n    get: function get() {\n      return this.closed_;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.clearAndClose = function () {\n    this.tensors.forEach(function (e) {\n      return e.tensor.dispose();\n    }), this.tensors = [], this.closed_ = !0;\n  }, e.prototype.size = function () {\n    return this.tensors.length;\n  }, e.prototype.read = function (e) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || e >= this.tensors.length) throw new Error(\"Tried to read from index \" + e + \", but array size is: \" + this.tensors.length);\n    var t = this.tensors[e];\n    if (t.cleared) throw new Error(\"TensorArray \" + this.name + \": Could not read index \" + e + \" twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).\");\n    return this.clearAfterRead && (t.cleared = !0), t.read = !0, t.tensor;\n  }, e.prototype.readMany = function (e) {\n    var t = this;\n    return e.map(function (e) {\n      return t.read(e);\n    });\n  }, e.prototype.write = function (e, t) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || !this.dynamicSize && e >= this.maxSize) throw new Error(\"Tried to write to index \" + e + \", but array is not resizeable and size is: \" + this.maxSize);\n    var a = this.tensors[e] || {};\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \",\\n          because the value dtype is \" + t.dtype + \", but TensorArray dtype is \" + this.dtype + \".\");\n    if (0 !== this.size() || null != this.elementShape && 0 !== this.elementShape.length || (this.elementShape = t.shape), this.assertShapesMatch(this.elementShape, t.shape, \"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \".\"), a && a.read) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been read.\");\n    if (a && a.written) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been written.\");\n    a.tensor = t, a.written = !0, this.tensors[e] = a;\n  }, e.prototype.writeMany = function (e, t) {\n    var a = this;\n    if (e.length !== t.length) throw new Error(\"TensorArray \" + this.name + \": could not write multiple tensors,because the index size: \" + e.length + \" is not the same as tensors size: \" + t.length + \".\");\n    e.forEach(function (e, r) {\n      return a.write(e, t[r]);\n    });\n  }, e.prototype.gather = function (e, t) {\n    if (t && t !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but gather requested dtype \" + t);\n\n    if (!e) {\n      e = [];\n\n      for (var a = 0; a < this.size(); a++) {\n        e.push(a);\n      }\n    }\n\n    if (0 === e.length) return tensor([], [0].concat(this.elementShape));\n    var r = this.readMany(e);\n    return this.assertShapesMatch(this.elementShape, r[0].shape, \"TensorArray shape mismatch: \"), stack(r, 0);\n  }, e.prototype.concat = function (e) {\n    if (e && e !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but concat requested dtype \" + e);\n    if (0 === this.size()) return tensor([], [0].concat(this.elementShape));\n\n    for (var t = [], a = 0; a < this.size(); a++) {\n      t.push(a);\n    }\n\n    var r = this.readMany(t);\n    return this.assertShapesMatch(this.elementShape, r[0].shape, \"TensorArray shape mismatch: tensor array shape (\" + this.elementShape + \") vs first tensor shape (\" + r[0].shape + \")\"), concat(r, 0);\n  }, e.prototype.scatter = function (e, t) {\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    if (e.length !== t.shape[0]) throw new Error(\"Expected len(indices) == tensor.shape[0], but saw: \" + e.length + \" vs. \" + t.shape[0]);\n    var a = Math.max.apply(Math, e);\n    if (!this.dynamicSize && a >= this.maxSize) throw new Error(\"Max index must be < array size (\" + a + \"  vs. \" + this.maxSize + \")\");\n    this.writeMany(e, unstack(t, 0));\n  }, e.prototype.split = function (e, t) {\n    var a = this;\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    var r = 0,\n        n = e.map(function (e) {\n      return r += e;\n    });\n    if (r !== t.shape[0]) throw new Error(\"Expected sum of lengths to be equal to\\n          tensor.shape[0], but sum of lengths is\\n        \" + r + \", and tensor's shape is: \" + t.shape);\n    if (!this.dynamicSize && e.length !== this.maxSize) throw new Error(\"TensorArray's size is not equal to the size of lengths (\" + this.maxSize + \" vs. \" + e.length + \"), and the TensorArray is not marked as dynamically resizeable\");\n    var o = 0 === r ? 0 : t.size / r,\n        s = [];\n    tidy(function () {\n      t = t.reshape([1, r, o]);\n\n      for (var i = 0; i < e.length; ++i) {\n        var p = [0, 0 === i ? 0 : n[i - 1], 0],\n            u = [1, e[i], o];\n        s[i] = slice(t, p, u).reshape(a.elementShape);\n      }\n\n      return s;\n    });\n\n    for (var i = [], p = 0; p < e.length; p++) {\n      i[p] = p;\n    }\n\n    this.writeMany(i, s);\n  }, e.prototype.assertShapesMatch = function (e, t, a) {\n    void 0 === a && (a = \"\"), util.assert(this.arraysEqual(e, t), a + \" Shapes \" + e + \" and \" + t + \" must match\");\n  }, e.prototype.arraysEqual = function (e, t) {\n    if (e.length !== t.length) return !1;\n\n    for (var a = 0; a < e.length; a++) {\n      if (-1 !== e[a] && -1 !== t[a] && e[a] !== t[a]) return !1;\n    }\n\n    return !0;\n  }, e.nextId = 0, e;\n}();\n\nfunction executeOp$2(e, t, a) {\n  return __awaiter(this, void 0, void 0, function () {\n    var r, n, o, s, i, p, u, m, l, d, c, f, y, h, g, N, P, b, x, I, v, O, w, V, T, _, k, S, A, D, $, E, M, j, R;\n\n    return __generator(this, function (L) {\n      switch (L.label) {\n        case 0:\n          switch (e.op) {\n            case \"loopCond\":\n              return [3, 1];\n\n            case \"switch\":\n              return [3, 2];\n\n            case \"merge\":\n              return [3, 4];\n\n            case \"enter\":\n              return [3, 5];\n\n            case \"exit\":\n              return [3, 6];\n\n            case \"nextIteration\":\n              return [3, 7];\n\n            case \"tensorArray\":\n              return [3, 8];\n\n            case \"tensorArrayWrite\":\n              return [3, 9];\n\n            case \"tensorArrayRead\":\n              return [3, 10];\n\n            case \"tensorArrayGather\":\n              return [3, 11];\n\n            case \"tensorArrayScatter\":\n              return [3, 12];\n\n            case \"tensorArrayConcat\":\n              return [3, 13];\n\n            case \"tensorArraySplit\":\n              return [3, 14];\n\n            case \"tensorArraySize\":\n              return [3, 15];\n\n            case \"tensorArrayClose\":\n              return [3, 16];\n          }\n\n          return [3, 17];\n\n        case 1:\n          return [2, [getParamValue(\"pred\", e, t, a).clone()]];\n\n        case 2:\n          return r = getParamValue(\"pred\", e, t, a), n = getParamValue(\"data\", e, t, a), [4, r.data()];\n\n        case 3:\n          return [2, L.sent()[0] ? [void 0, n.clone()] : [n.clone(), void 0]];\n\n        case 4:\n          return [2, (o = e.inputNames.find(function (e) {\n            return void 0 !== getTensor(e, t, a);\n          })) ? [getTensor(o, t, a).clone()] : void 0];\n\n        case 5:\n          return s = getParamValue(\"frameName\", e, t, a), i = getParamValue(\"tensor\", e, t, a), a.enterFrame(s), [2, [i.clone()]];\n\n        case 6:\n          return p = getParamValue(\"tensor\", e, t, a), a.exitFrame(), [2, [p.clone()]];\n\n        case 7:\n          return u = getParamValue(\"tensor\", e, t, a), a.nextIteration(), [2, [u.clone()]];\n\n        case 8:\n          return m = getParamValue(\"size\", e, t, a), l = getParamValue(\"dtype\", e, t, a), d = getParamValue(\"elementShape\", e, t, a), c = getParamValue(\"dynamicSize\", e, t, a), f = getParamValue(\"clearAfterRead\", e, t, a), y = getParamValue(\"identicalElementShapes\", e, t, a), h = getParamValue(\"name\", e, t, a), g = new TensorArray(h, l, m, d, y, c, f), a.addTensorArray(g), [2, [scalar(g.id), scalar(1)]];\n\n        case 9:\n          return N = getParamValue(\"tensorArrayId\", e, t, a), P = getParamValue(\"index\", e, t, a), b = getParamValue(\"tensor\", e, t, a), a.getTensorArray(N).write(P, b), [2, [scalar(1)]];\n\n        case 10:\n          return x = getParamValue(\"tensorArrayId\", e, t, a), I = getParamValue(\"index\", e, t, a), [2, [a.getTensorArray(x).read(I)]];\n\n        case 11:\n          return v = getParamValue(\"tensorArrayId\", e, t, a), O = getParamValue(\"indices\", e, t, a), w = getParamValue(\"dtype\", e, t, a), [2, [a.getTensorArray(v).gather(O, w)]];\n\n        case 12:\n          return V = getParamValue(\"tensorArrayId\", e, t, a), T = getParamValue(\"indices\", e, t, a), _ = getParamValue(\"tensor\", e, t, a), a.getTensorArray(V).scatter(T, _), [2, [scalar(1)]];\n\n        case 13:\n          return k = getParamValue(\"tensorArrayId\", e, t, a), S = a.getTensorArray(k), A = getParamValue(\"dtype\", e, t, a), [2, [S.concat(A)]];\n\n        case 14:\n          return D = getParamValue(\"tensorArrayId\", e, t, a), $ = getParamValue(\"tensor\", e, t, a), E = getParamValue(\"lengths\", e, t, a), a.getTensorArray(D).split(E, $), [2, [scalar(1)]];\n\n        case 15:\n          return M = getParamValue(\"tensorArrayId\", e, t, a), j = a.getTensorArray(M), [2, [scalar(j.size(), \"int32\")]];\n\n        case 16:\n          return R = getParamValue(\"tensorArrayId\", e, t, a), a.getTensorArray(R).clearAndClose(), [2, []];\n\n        case 17:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n}\n\nvar executeOp$3 = function executeOp$3(e, t, a) {\n  switch (e.op) {\n    case \"conv1d\":\n      var r = getParamValue(\"stride\", e, t, a),\n          n = getParamValue(\"pad\", e, t, a),\n          o = getParamValue(\"dataFormat\", e, t, a).toUpperCase(),\n          s = getParamValue(\"dilation\", e, t, a);\n      return [conv1d(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), r, n, o, s)];\n\n    case \"conv2d\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), o = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      var i = getParamValue(\"dilations\", e, t, a);\n      return [conv2d(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, o, [i[0], i[1]])];\n\n    case \"conv2dTranspose\":\n      var p = getParamValue(\"outputShape\", e, t, a);\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      return [conv2dTranspose(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), p, [r[1], r[2]], n)];\n\n    case \"depthwiseConv2d\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), i = getParamValue(\"dilations\", e, t, a), o = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [depthwiseConv2d(getParamValue(\"input\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, o, [i[0], i[1]])];\n\n    case \"avgPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      var u = getParamValue(\"kernelSize\", e, t, a);\n      return [avgPool(getParamValue(\"x\", e, t, a), [u[1], u[2]], [r[1], r[2]], n)];\n\n    case \"maxPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), u = getParamValue(\"kernelSize\", e, t, a);\n      return [maxPool(getParamValue(\"x\", e, t, a), [u[1], u[2]], [r[1], r[2]], n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$4 = function executeOp$4(e, t, a) {\n  switch (e.op) {\n    case \"fill\":\n      var r = getParamValue(\"shape\", e, t, a),\n          n = getParamValue(\"dtype\", e, t, a),\n          o = getParamValue(\"value\", e, t, a);\n      return [fill(r, o, n)];\n\n    case \"linspace\":\n      var s = getParamValue(\"start\", e, t, a),\n          i = getParamValue(\"stop\", e, t, a),\n          p = getParamValue(\"num\", e, t, a);\n      return [linspace(s, i, p)];\n\n    case \"oneHot\":\n      var u = getParamValue(\"indices\", e, t, a),\n          m = getParamValue(\"depth\", e, t, a),\n          l = getParamValue(\"onValue\", e, t, a),\n          d = getParamValue(\"offValue\", e, t, a);\n      return [oneHot(u, m, l, d)];\n\n    case \"ones\":\n      return [ones(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"onesLike\":\n      return [onesLike(getParamValue(\"x\", e, t, a))];\n\n    case \"randomUniform\":\n      return [randomUniform(getParamValue(\"shape\", e, t, a), getParamValue(\"minval\", e, t, a), getParamValue(\"maxval\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"range\":\n      s = getParamValue(\"start\", e, t, a);\n      var c = getParamValue(\"stop\", e, t, a),\n          f = getParamValue(\"step\", e, t, a);\n      return [range(s, c, f, getParamValue(\"dtype\", e, t, a))];\n\n    case \"truncatedNormal\":\n      r = getParamValue(\"shape\", e, t, a);\n      var y = getParamValue(\"mean\", e, t, a),\n          h = getParamValue(\"stdDev\", e, t, a),\n          g = getParamValue(\"seed\", e, t, a);\n      return [truncatedNormal(r, y, h, getParamValue(\"dtype\", e, t, a), g)];\n\n    case \"zeros\":\n      return [zeros(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"zerosLike\":\n      return [zerosLike(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n};\n\nfunction executeOp$5(e, t, a) {\n  return __awaiter(this, void 0, void 0, function () {\n    var r, n, o, s, i;\n    return __generator(this, function (p) {\n      switch (p.label) {\n        case 0:\n          switch (e.op) {\n            case \"nonMaxSuppression\":\n              return [3, 1];\n\n            case \"whereAsync\":\n              return [3, 3];\n\n            case \"setdiff1dAsync\":\n              return [3, 5];\n          }\n\n          return [3, 7];\n\n        case 1:\n          return r = getParamValue(\"boxes\", e, t, a), n = getParamValue(\"scores\", e, t, a), o = getParamValue(\"maxOutputSize\", e, t, a), s = getParamValue(\"iouThreshold\", e, t, a), i = getParamValue(\"scoreThreshold\", e, t, a), [4, image.nonMaxSuppressionAsync(r, n, o, s, i)];\n\n        case 2:\n          return [2, [p.sent()]];\n\n        case 3:\n          return [4, whereAsync(getParamValue(\"condition\", e, t, a))];\n\n        case 4:\n          return [2, [p.sent()]];\n\n        case 5:\n          return [4, setdiff1dAsync(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n        case 6:\n          return [2, p.sent()];\n\n        case 7:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n}\n\nvar executeOp$6 = function executeOp$6(e, t, a) {\n  switch (e.op) {\n    case \"topK\":\n      var r = getParamValue(\"x\", e, t, a),\n          n = getParamValue(\"k\", e, t, a),\n          o = getParamValue(\"sorted\", e, t, a),\n          s = topk(r, n, o);\n      return [s.values, s.indices];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$7 = function executeOp$7(e, t, a) {\n  switch (e.op) {\n    case \"const\":\n      return t[e.name];\n\n    case \"placeholder\":\n      var r = getParamValue(\"default\", e, t, a);\n      return [getTensor(e.name, t, a) || r];\n\n    case \"identity\":\n    case \"stopGradient\":\n    case \"fakeQuantWithMinMaxVars\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"snapshot\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"shape\":\n      return [tensor1d(getParamValue(\"x\", e, t, a).shape, \"int32\")];\n\n    case \"shapeN\":\n      return getParamValue(\"x\", e, t, a).map(function (e) {\n        return tensor1d(e.shape);\n      });\n\n    case \"size\":\n      return [scalar(getParamValue(\"x\", e, t, a).size, \"int32\")];\n\n    case \"rank\":\n      return [scalar(getParamValue(\"x\", e, t, a).rank, \"int32\")];\n\n    case \"noop\":\n      return [];\n\n    case \"print\":\n      var n = getParamValue(\"x\", e, t, a),\n          o = getParamValue(\"data\", e, t, a),\n          s = getParamValue(\"message\", e, t, a),\n          i = getParamValue(\"summarize\", e, t, a);\n      console.warn(\"The graph has a tf.print() operation,usually used for debugging, which slows down performance.\"), console.log(s);\n\n      for (var p = 0; p < o.length; p++) {\n        console.log(Array.prototype.slice.call(o[0].dataSync()).slice(0, i));\n      }\n\n      return [n];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$8 = function executeOp$8(e, t, a) {\n  switch (e.op) {\n    case \"resizeBilinear\":\n      var r = getParamValue(\"images\", e, t, a),\n          n = getParamValue(\"size\", e, t, a),\n          o = getParamValue(\"alignCorners\", e, t, a);\n      return [image.resizeBilinear(r, [n[0], n[1]], o)];\n\n    case \"resizeNearestNeighbor\":\n      r = getParamValue(\"images\", e, t, a), n = getParamValue(\"size\", e, t, a), o = getParamValue(\"alignCorners\", e, t, a);\n      return [image.resizeNearestNeighbor(r, [n[0], n[1]], o)];\n\n    case \"cropAndResize\":\n      var s = getParamValue(\"image\", e, t, a),\n          i = getParamValue(\"boxes\", e, t, a),\n          p = getParamValue(\"boxInd\", e, t, a),\n          u = getParamValue(\"cropSize\", e, t, a),\n          m = getParamValue(\"method\", e, t, a),\n          l = getParamValue(\"extrapolationValue\", e, t, a);\n      return [image.cropAndResize(s, i, p, u, m, l)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$9 = function executeOp$9(e, t, a) {\n  switch (e.op) {\n    case \"equal\":\n      return [equal(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"notEqual\":\n      return [notEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"greater\":\n      return [greater(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"greaterEqual\":\n      return [greaterEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"less\":\n      return [less(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"lessEqual\":\n      return [lessEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"logicalAnd\":\n      return [logicalAnd(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"logicalNot\":\n      return [logicalNot(getParamValue(\"a\", e, t, a))];\n\n    case \"logicalOr\":\n      return [logicalOr(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"where\":\n      return [where(getParamValue(\"condition\", e, t, a), getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$10 = function executeOp$10(e, t, a) {\n  switch (e.op) {\n    case \"matMul\":\n      return [matMul(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a), getParamValue(\"transposeA\", e, t, a), getParamValue(\"transposeB\", e, t, a))];\n\n    case \"transpose\":\n      return [transpose(getParamValue(\"x\", e, t, a), getParamValue(\"perm\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$11 = function executeOp$11(e, t, a) {\n  switch (e.op) {\n    case \"batchNormalization\":\n      return [batchNorm(getParamValue(\"x\", e, t, a), getParamValue(\"mean\", e, t, a), getParamValue(\"variance\", e, t, a), getParamValue(\"offset\", e, t, a), getParamValue(\"scale\", e, t, a), getParamValue(\"epsilon\", e, t, a))];\n\n    case \"localResponseNormalization\":\n      return [localResponseNormalization(getParamValue(\"x\", e, t, a), getParamValue(\"radius\", e, t, a), getParamValue(\"bias\", e, t, a), getParamValue(\"alpha\", e, t, a), getParamValue(\"beta\", e, t, a))];\n\n    case \"softmax\":\n      return [softmax(getParamValue(\"x\", e, t, a))];\n\n    case \"logSoftmax\":\n      return [logSoftmax(getParamValue(\"x\", e, t, a))];\n\n    case \"sparseToDense\":\n      return [sparseToDense(getParamValue(\"sparseIndices\", e, t, a), getParamValue(\"outputShape\", e, t, a), getParamValue(\"sparseValues\", e, t, a), getParamValue(\"defaultValue\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$12 = function executeOp$12(e, t, a) {\n  switch (e.op) {\n    case \"max\":\n      var r = getParamValue(\"axis\", e, t, a),\n          n = getParamValue(\"keepDims\", e, t, a);\n      return [max(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"mean\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [mean(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"min\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [min(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"sum\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [sum(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"all\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [all(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"any\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [any(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"argMax\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [argMax(getParamValue(\"x\", e, t, a), r)];\n\n    case \"argMin\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [argMin(getParamValue(\"x\", e, t, a), r)];\n\n    case \"prod\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [prod(getParamValue(\"x\", e, t, a), r, n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$13 = function executeOp$13(e, t, a) {\n  switch (e.op) {\n    case \"concat\":\n      var r = getParamValue(\"axis\", e, t, a),\n          n = getParamValue(\"tensors\", e, t, a);\n      return [concat(n, r)];\n\n    case \"gather\":\n      r = getParamValue(\"axis\", e, t, a);\n      var o = getParamValue(\"x\", e, t, a),\n          s = getParamValue(\"indices\", e, t, a);\n      return [gather(o, s, r)];\n\n    case \"reverse\":\n      r = getParamValue(\"axis\", e, t, a), o = getParamValue(\"x\", e, t, a);\n      return [reverse(o, r)];\n\n    case \"slice\":\n      var i = getParamValue(\"begin\", e, t, a),\n          p = getParamValue(\"size\", e, t, a);\n      return [slice(getParamValue(\"x\", e, t, a), i, p)];\n\n    case \"stridedSlice\":\n      i = getParamValue(\"begin\", e, t, a);\n      var u = getParamValue(\"end\", e, t, a),\n          m = getParamValue(\"strides\", e, t, a),\n          l = getParamValue(\"beginMask\", e, t, a),\n          d = getParamValue(\"endMask\", e, t, a),\n          c = getParamValue(\"ellipsisMask\", e, t, a),\n          f = getParamValue(\"newAxisMask\", e, t, a),\n          y = getParamValue(\"shrinkAxisMask\", e, t, a),\n          h = getParamValue(\"x\", e, t, a);\n      if (1 === i.length && h.shape.length > 1) for (var g = 1; g < h.shape.length; g++) {\n        i.push(0), u.push(h.shape[g]), m.push(m[0]);\n      }\n      return [stridedSlice(h, i, u, m, l, d, c, f, y)];\n\n    case \"stack\":\n      return tidy(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensors\", e, t, a),\n            o = n[0].shape,\n            s = n[0].squeeze().shape,\n            i = n.map(function (e) {\n          var t = util.arraysEqual(e.shape, o);\n          if (!t && !util.arraysEqual(e.squeeze().shape, s)) throw new Error(\"the input tensors shape does not match\");\n          return t ? e : e.reshape(o);\n        });\n        return [stack(i, r)];\n      });\n\n    case \"unstack\":\n      return tidy(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensor\", e, t, a);\n        return unstack(n, r);\n      });\n\n    case \"tile\":\n      var N = getParamValue(\"reps\", e, t, a);\n      return [tile(getParamValue(\"x\", e, t, a), N)];\n\n    case \"split\":\n      r = getParamValue(\"axis\", e, t, a);\n      var P = getParamValue(\"numOrSizeSplits\", e, t, a);\n      return split(getParamValue(\"x\", e, t, a), P, r);\n\n    case \"scatterNd\":\n      s = getParamValue(\"indices\", e, t, a);\n      var b = getParamValue(\"values\", e, t, a),\n          x = getParamValue(\"shape\", e, t, a);\n      return [scatterND(s, b, x)];\n\n    case \"gatherNd\":\n      var I = getParamValue(\"x\", e, t, a);\n      s = getParamValue(\"indices\", e, t, a);\n      return [gatherND(I, s)];\n\n    case \"sparseToDense\":\n      s = getParamValue(\"sparseIndices\", e, t, a), x = getParamValue(\"outputShape\", e, t, a);\n      var v = getParamValue(\"sparseValues\", e, t, a),\n          O = getParamValue(\"defaultValue\", e, t, a);\n      return [sparseToDense(s, v, x, O)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$14 = function executeOp$14(e, t, a) {\n  switch (e.op) {\n    case \"fft\":\n      return [fft(getParamValue(\"x\", e, t, a))];\n\n    case \"ifft\":\n      return [ifft(getParamValue(\"x\", e, t, a))];\n\n    case \"rfft\":\n      return [rfft(getParamValue(\"x\", e, t, a))];\n\n    case \"irfft\":\n      return [irfft(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$15 = function executeOp$15(e, t, a) {\n  switch (e.op) {\n    case \"cast\":\n      return [cast(getParamValue(\"x\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"expandDims\":\n      var r = getParamValue(\"axis\", e, t, a);\n      return [expandDims(getParamValue(\"x\", e, t, a), r)];\n\n    case \"squeeze\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [squeeze(getParamValue(\"x\", e, t, a), r)];\n\n    case \"reshape\":\n      return [reshape(getParamValue(\"x\", e, t, a), getParamValue(\"shape\", e, t, a))];\n\n    case \"pad\":\n      return [pad(getParamValue(\"x\", e, t, a), split$1(getParamValue(\"padding\", e, t, a), 2), getParamValue(\"constantValue\", e, t, a))];\n\n    case \"spaceToBatchND\":\n      var n = getParamValue(\"blockShape\", e, t, a),\n          o = split$1(getParamValue(\"paddings\", e, t, a), 2);\n      return [spaceToBatchND(getParamValue(\"x\", e, t, a), n, o)];\n\n    case \"batchToSpaceND\":\n      n = getParamValue(\"blockShape\", e, t, a);\n      var s = split$1(getParamValue(\"crops\", e, t, a), 2);\n      return [batchToSpaceND(getParamValue(\"x\", e, t, a), n, s)];\n\n    case \"depthToSpace\":\n      var i = getParamValue(\"blockSize\", e, t, a),\n          p = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [depthToSpace(getParamValue(\"x\", e, t, a), i, p)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n};\n\nfunction executeOp$16(e, t, a) {\n  switch (e.category) {\n    case \"arithmetic\":\n      return executeOp(e, t, a);\n\n    case \"basic_math\":\n      return executeOp$1(e, t, a);\n\n    case \"control\":\n      return executeOp$2(e, t, a);\n\n    case \"convolution\":\n      return executeOp$3(e, t, a);\n\n    case \"creation\":\n      return executeOp$4(e, t, a);\n\n    case \"dynamic\":\n      return executeOp$5(e, t, a);\n\n    case \"evaluation\":\n      return executeOp$6(e, t, a);\n\n    case \"image\":\n      return executeOp$8(e, t, a);\n\n    case \"graph\":\n      return executeOp$7(e, t, a);\n\n    case \"logical\":\n      return executeOp$9(e, t, a);\n\n    case \"matrices\":\n      return executeOp$10(e, t, a);\n\n    case \"normalization\":\n      return executeOp$11(e, t, a);\n\n    case \"reduction\":\n      return executeOp$12(e, t, a);\n\n    case \"slice_join\":\n      return executeOp$13(e, t, a);\n\n    case \"spectral\":\n      return executeOp$14(e, t, a);\n\n    case \"transformation\":\n      return executeOp$15(e, t, a);\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n}\n\nvar ExecutionContext = function () {\n  function e(e, t) {\n    this.weightMap = e, this.tensorArrayMap = t, this.rootContext = {\n      id: 0,\n      frameName: \"\",\n      iterationId: 0\n    }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();\n  }\n\n  return e.prototype.newFrame = function (e, t) {\n    return {\n      id: e,\n      frameName: t,\n      iterationId: 0\n    };\n  }, Object.defineProperty(e.prototype, \"currentContext\", {\n    get: function get() {\n      return this.contexts;\n    },\n    set: function set(e) {\n      this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextId\", {\n    get: function get() {\n      return this._currentContextIds[0];\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextIds\", {\n    get: function get() {\n      return this._currentContextIds;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.generateCurrentContextIds = function () {\n    for (var e = [], t = 0; t < this.contexts.length - 1; t++) {\n      var a = this.contexts.slice(0, this.contexts.length - t);\n      e.push(this.contextIdforContexts(a));\n    }\n\n    e.push(\"\"), this._currentContextIds = e;\n  }, e.prototype.contextIdforContexts = function (e) {\n    return e ? e.map(function (e) {\n      return 0 === e.id && 0 === e.iterationId ? \"\" : e.frameName + \"-\" + e.iterationId;\n    }).join(\"/\") : \"\";\n  }, e.prototype.enterFrame = function (e) {\n    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));\n  }, e.prototype.exitFrame = function () {\n    if (!(this.contexts && this.contexts.length > 1)) throw new Error(\"Cannot exit frame, the context is empty\");\n    this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();\n  }, e.prototype.nextIteration = function () {\n    if (!(this.contexts && this.contexts.length > 0)) throw new Error(\"Cannot increase frame iteration, the context is empty\");\n    this.contexts = this.contexts.slice(), this.lastId++;\n    var e = Object.assign({}, this.contexts[this.contexts.length - 1]);\n    e.iterationId += 1, e.id = this.lastId, this.contexts.splice(-1, 1, e), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));\n  }, e.prototype.getWeight = function (e) {\n    return this.weightMap[e];\n  }, e.prototype.addTensorArray = function (e) {\n    this.tensorArrayMap[e.id] = e;\n  }, e.prototype.getTensorArray = function (e) {\n    return this.tensorArrayMap[e];\n  }, e;\n}(),\n    GraphExecutor = function () {\n  function e(e) {\n    this.graph = e, this.compiledMap = new Map(), this._weightMap = {}, this.SEPERATOR = \",\", this.placeholders = e.placeholders, this._outputs = e.outputs, this.compile();\n  }\n\n  return Object.defineProperty(e.prototype, \"weightMap\", {\n    get: function get() {\n      return this._weightMap;\n    },\n    set: function set(e) {\n      var t = Object.keys(e).map(function (t) {\n        return e[t].map(function (e) {\n          return e.id;\n        });\n      });\n      this.weightIds = [].concat.apply([], t), this._weightMap = e;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function get() {\n      return this.placeholders.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.params.shape ? e.params.shape.value : void 0,\n          dtype: e.params.dtype ? e.params.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function get() {\n      return this._outputs.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.params.shape ? e.params.shape.value : void 0,\n          dtype: e.params.dtype ? e.params.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function get() {\n      return this.placeholders.map(function (e) {\n        return e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function get() {\n      return this.outputs.map(function (e) {\n        return e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"isControlFlowModel\", {\n    get: function get() {\n      return this.graph.withControlFlow;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"isDynamicShapeModel\", {\n    get: function get() {\n      return this.graph.withDynamicShape;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.compile = function (e) {\n    if (!this.graph.withControlFlow && !this.graph.withDynamicShape) {\n      var t = [],\n          a = e || this.graph.placeholders,\n          r = a.map(function (e) {\n        return e.name;\n      }).sort().join(this.SEPERATOR);\n\n      if (!this.compiledMap.get(r)) {\n        for (var n = a.concat(this.graph.weights), o = {}; n.length > 0;) {\n          var s = n.pop();\n          o[s.name] = !0, t.push(s), s.children.forEach(function (e) {\n            !o[e.name] && e.inputNames.every(function (e) {\n              var t = getNodeNameAndIndex(e)[0];\n              return o[t];\n            }) && n.push(e);\n          });\n        }\n\n        this.compiledMap.set(r, t);\n      }\n    }\n  }, e.prototype.execute = function (e, t, a) {\n    var r = this;\n    void 0 === t && (t = !0);\n    var n = Object.keys(e).sort();\n    this.checkInput(e, t), this.checkInputShapeAndType(e, t), this.compile(n.map(function (e) {\n      return r.graph.nodes[e];\n    }));\n    var o = this.calculateOutputs(a);\n    this.checkOutput(this.compiledMap.get(n.join(this.SEPERATOR)), o);\n    var s = {};\n    return tidy(function () {\n      for (var t = new ExecutionContext(r._weightMap, s), a = __assign({}, r.weightMap, e), i = r.getFrozenTensorIds(a), p = {}, u = r.compiledMap.get(n.join(r.SEPERATOR)), m = 0; m < u.length; m++) {\n        var l = u[m];\n        if (a[l.name] || (a[l.name] = executeOp$16(l, a, t), r.checkTensorForDisposal(l.name, l, a, t, i, o, p)), o.every(function (e) {\n          return !!a[e];\n        })) break;\n      }\n\n      return r.findOutputs(a, t, o);\n    });\n  }, e.prototype.getFrozenTensorIds = function (e) {\n    var t = [].concat.apply([], Object.keys(e).map(function (t) {\n      return e[t];\n    }).map(function (e) {\n      return e.map(function (e) {\n        return e.id;\n      });\n    }));\n    return new Set(t);\n  }, e.prototype.checkTensorForDisposal = function (e, t, a, r, n, o, s) {\n    \"control\" !== t.category && -1 === o.indexOf(e) && (a[e].forEach(function (e) {\n      null != e && (s[e.id] = (s[e.id] || 0) + t.children.length);\n    }), t.inputs.forEach(function (e) {\n      if (\"control\" !== e.category) {\n        var t = getTensorsForCurrentContenxt(e.name, a, r);\n        null != t && t.forEach(function (e) {\n          if (e && !n.has(e.id)) {\n            var t = s[e.id];\n            1 === t ? (e.dispose(), delete s[e.id]) : null != t && s[e.id]--;\n          }\n        });\n      }\n    }));\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a,\n          r,\n          n,\n          o,\n          s,\n          i,\n          p,\n          u,\n          m = this;\n      return __generator(this, function (l) {\n        switch (l.label) {\n          case 0:\n            return this.checkInput(e, !1), this.checkInputShapeAndType(e, !1), a = {}, r = new ExecutionContext(this._weightMap, a), n = this.calculateOutputs(t), [4, this.executeWithControlFlow(e, r, n)];\n\n          case 1:\n            return o = l.sent(), s = this.findOutputs(o, r, t), i = Object.keys(s).map(function (e) {\n              return s[e].id;\n            }), p = Object.keys(e).map(function (t) {\n              return e[t].map(function (e) {\n                return e.id;\n              });\n            }), u = [].concat.apply([], p), Object.keys(o).forEach(function (e) {\n              o[e].forEach(function (e) {\n                e && -1 === i.indexOf(e.id) && -1 === u.indexOf(e.id) && -1 === m.weightIds.indexOf(e.id) && e.dispose();\n              });\n            }), [2, s];\n        }\n      });\n    });\n  }, e.prototype.executeWithControlFlow = function (e, t, a) {\n    return __awaiter(this, void 0, void 0, function () {\n      var r,\n          n,\n          o,\n          s,\n          i,\n          p,\n          u,\n          m,\n          l = this;\n      return __generator(this, function (d) {\n        switch (d.label) {\n          case 0:\n            r = Object.keys(e), n = r.map(function (e) {\n              return l.graph.nodes[e];\n            }), o = n.concat(this.graph.weights).map(function (e) {\n              return {\n                node: e,\n                contexts: t.currentContext\n              };\n            }), s = __assign({}, this.weightMap, e), i = {}, p = this.getFrozenTensorIds(s), u = {}, d.label = 1;\n\n          case 1:\n            return o.length > 0 ? (m = this.processStack(n, o, t, s, u, p, a, i), [4, Promise.all(m)]) : [3, 3];\n\n          case 2:\n            return d.sent(), [3, 1];\n\n          case 3:\n            return [2, s];\n        }\n      });\n    });\n  }, e.prototype.processStack = function (e, t, a, r, n, o, s, i) {\n    for (var p = this, u = [], m = function m() {\n      var m = t.pop();\n      a.currentContext = m.contexts;\n      var d = \"\";\n\n      if (\"enter\" === m.node.op && getParamValue(\"isConstant\", m.node, r, a) && (d = getNodeNameAndIndex(m.node.name, a)[0]), -1 === e.indexOf(m.node)) {\n        var c = executeOp$16(m.node, r, a);\n        d || (d = getNodeNameAndIndex(m.node.name, a)[0]);\n        var f = a.currentContext;\n        c instanceof Promise ? u.push(c.then(function (e) {\n          return r[d] = e, a.currentContext = f, p.checkTensorForDisposal(d, m.node, r, a, o, s, i), p.processChildNodes(m.node, t, a, r, n), e;\n        })) : (r[d] = c, l.checkTensorForDisposal(d, m.node, r, a, o, s, i), l.processChildNodes(m.node, t, a, r, n));\n      } else l.processChildNodes(m.node, t, a, r, n);\n    }, l = this; t.length > 0;) {\n      m();\n    }\n\n    return u;\n  }, e.prototype.processChildNodes = function (e, t, a, r, n) {\n    e.children.forEach(function (e) {\n      var o = getNodeNameAndIndex(e.name, a)[0];\n      n[o] || (\"merge\" === e.op ? e.inputNames.some(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })) : e.inputNames.every(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })));\n    });\n  }, e.prototype.calculateOutputs = function (e) {\n    return !e || e instanceof Array || (e = [e]), e || this.graph.outputs.map(function (e) {\n      return e.name;\n    });\n  }, e.prototype.findOutputs = function (e, t, a) {\n    return this.calculateOutputs(a).reduce(function (a, r) {\n      return a[r] = getTensor(r, e, t), a;\n    }, {});\n  }, e.prototype.dispose = function () {\n    var e = this;\n    Object.keys(this.weightMap).forEach(function (t) {\n      return e.weightMap[t].forEach(function (e) {\n        return e.dispose();\n      });\n    });\n  }, e.prototype.checkInputShapeAndType = function (e, t) {\n    void 0 === t && (t = !0), this.placeholders.forEach(function (a) {\n      var r = e[a.name];\n\n      if (t || r) {\n        var n = r[0];\n\n        if (a.params.shape && a.params.shape.value) {\n          var o = a.params.shape.value,\n              s = o.length === n.shape.length && n.shape.every(function (e, t) {\n            return -1 === o[t] || o[t] === e;\n          });\n          util.assert(s, \"The shape of dict['\" + a.name + \"'] provided in model.execute(dict) must be [\" + o + \"], but was [\" + n.shape + \"]\");\n        }\n\n        a.params.dtype && a.params.dtype.value && util.assert(n.dtype === a.params.dtype.value, \"The dtype of dict['\" + a.name + \"'] provided in model.execute(dict) must be \" + a.params.dtype.value + \", but was \" + n.dtype);\n      }\n    });\n  }, e.prototype.checkInput = function (e, t) {\n    var a = this;\n    void 0 === t && (t = !0);\n    var r = Object.keys(e),\n        n = [],\n        o = [];\n    this.inputNodes.forEach(function (e) {\n      -1 === r.indexOf(e) && n.push(e);\n    }), r.forEach(function (e) {\n      -1 === a.inputNodes.indexOf(e) && o.push(e);\n    });\n    var s = o.filter(function (e) {\n      return !a.graph.nodes[e];\n    });\n    if (n.length > 0 && t) throw new Error(\"The dict provided in model.execute(dict) has the keys [\" + r + \"], but is missing the required keys: [\" + n + \"].\");\n    if (o.length > 0 && t) throw new Error(\"The dict provided in model.execute(dict) has unused keys: [\" + o + \"]. Please provide only the following keys: [\" + this.inputNodes + \"].\");\n    if (s.length > 0) throw new Error(\"The dict provided in model.execute(dict) has keys: [\" + s + \"] not part of model graph.\");\n  }, e.prototype.checkOutput = function (e, t) {\n    var a = e.map(function (e) {\n      return e.name;\n    }),\n        r = [];\n    if (t.forEach(function (e) {\n      var t = parseNodeName(e)[0];\n      -1 === a.indexOf(t) && r.push(t);\n    }), r.length > 0) throw new Error(\"The following outputs are not generated by the execution: [\" + r + \"].\");\n  }, e;\n}(),\n    TFHUB_SEARCH_PARAM = \"?tfjs-format=file\",\n    DEFAULT_MODEL_NAME = \"tensorflowjs_model.pb\",\n    DEFAULT_MANIFEST_NAME = \"weights_manifest.json\",\n    FrozenModel = function () {\n  function e(e, t, a, r, n) {\n    this.modelUrl = e, this.weightManifestUrl = t, this.requestOption = a, this.weightPrefix = r, this.onProgress = n, this.version = \"n/a\";\n  }\n\n  return Object.defineProperty(e.prototype, \"modelVersion\", {\n    get: function get() {\n      return this.version;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function get() {\n      return this.executor.inputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function get() {\n      return this.executor.outputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function get() {\n      return this.executor.inputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function get() {\n      return this.executor.outputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"weights\", {\n    get: function get() {\n      return this.executor.weightMap;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.findIOHandler = function () {\n    var e = [this.modelUrl, this.weightManifestUrl];\n    if (this.requestOption || this.weightPrefix) this.handler = io.browserHTTPRequest(e, this.requestOption, this.weightPrefix, null, this.onProgress);else {\n      var t = io.getLoadHandlers(e, this.onProgress);\n      if (0 === t.length) t.push(io.browserHTTPRequest(e, this.requestOption, this.weightPrefix, null, this.onProgress));else if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") load handlers for URL '\" + [e] + \"'\");\n      this.handler = t[0];\n    }\n  }, e.prototype.load = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var e, t, a;\n      return __generator(this, function (r) {\n        switch (r.label) {\n          case 0:\n            if (this.findIOHandler(), null == this.handler.load) throw new Error(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n            return [4, this.handler.load()];\n\n          case 1:\n            return e = r.sent(), t = compiled_api_1.GraphDef.decode(new Uint8Array(e.modelTopology)), this.version = t.versions.producer + \".\" + t.versions.minConsumer, a = io.decodeWeights(e.weightData, e.weightSpecs), this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(t)), this.executor.weightMap = this.convertTensorMapToTensorsMap(a), [2, !0];\n        }\n      });\n    });\n  }, e.prototype.predict = function (e, t) {\n    return this.execute_(e, !0, this.outputNodes);\n  }, e.prototype.constructTensorMap = function (e) {\n    var t = e instanceof Tensor ? [e] : e;\n    if (t.length !== this.inputNodes.length) throw new Error(\"Input tensor count mismatch,the frozen model has \" + this.inputNodes.length + \" placeholders, while there are \" + t.length + \" input tensors.\");\n    return this.inputNodes.reduce(function (e, a, r) {\n      return e[a] = t[r], e;\n    }, {});\n  }, e.prototype.execute = function (e, t) {\n    return this.execute_(e, !1, t);\n  }, e.prototype.execute_ = function (e, t, a) {\n    if (void 0 === t && (t = !0), a = a || this.outputNodes, (e instanceof Tensor || Array.isArray(e)) && (e = this.constructTensorMap(e)), this.executor.isControlFlowModel || this.executor.isDynamicShapeModel) throw new Error(\"The model contains control flow or dynamic shape ops, please use executeAsync method\");\n    var r = this.executor.execute(this.convertTensorMapToTensorsMap(e), t, a),\n        n = Object.keys(r);\n    return Array.isArray(a) && a.length > 1 ? a.map(function (e) {\n      return r[e];\n    }) : r[n[0]];\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a, r;\n      return __generator(this, function (n) {\n        switch (n.label) {\n          case 0:\n            if (!this.executor.isControlFlowModel && !this.executor.isDynamicShapeModel) throw new Error(\"The model does not contain control flow or dynamic shape ops, please use execute method for better performance.\");\n            return t = t || this.outputNodes, (e instanceof Tensor || Array.isArray(e)) && (e = this.constructTensorMap(e)), [4, this.executor.executeAsync(this.convertTensorMapToTensorsMap(e), t)];\n\n          case 1:\n            return a = n.sent(), r = Object.keys(a), [2, Array.isArray(t) && t.length > 1 ? t.map(function (e) {\n              return a[e];\n            }) : a[r[0]]];\n        }\n      });\n    });\n  }, e.prototype.convertTensorMapToTensorsMap = function (e) {\n    return Object.keys(e).reduce(function (t, a) {\n      return t[a] = [e[a]], t;\n    }, {});\n  }, e.prototype.dispose = function () {\n    this.executor.dispose();\n  }, e;\n}(),\n    tensorflow_json;\n\nfunction loadFrozenModel(e, t, a, r) {\n  return __awaiter(this, void 0, void 0, function () {\n    var n;\n    return __generator(this, function (o) {\n      switch (o.label) {\n        case 0:\n          return [4, (n = new FrozenModel(e, t, a, null, r)).load()];\n\n        case 1:\n          return o.sent(), [2, n];\n      }\n    });\n  });\n}\n\nfunction loadTfHubModule(e, t, a) {\n  return __awaiter(this, void 0, void 0, function () {\n    return __generator(this, function (r) {\n      return e.endsWith(\"/\") || (e += \"/\"), [2, loadFrozenModel(\"\" + e + DEFAULT_MODEL_NAME + TFHUB_SEARCH_PARAM, \"\" + e + DEFAULT_MANIFEST_NAME + TFHUB_SEARCH_PARAM, t, a)];\n    });\n  });\n}\n\n!function (e) {\n  !function (e) {\n    e[e.DT_INVALID = 0] = \"DT_INVALID\", e[e.DT_FLOAT = 1] = \"DT_FLOAT\", e[e.DT_DOUBLE = 2] = \"DT_DOUBLE\", e[e.DT_INT32 = 3] = \"DT_INT32\", e[e.DT_UINT8 = 4] = \"DT_UINT8\", e[e.DT_INT16 = 5] = \"DT_INT16\", e[e.DT_INT8 = 6] = \"DT_INT8\", e[e.DT_STRING = 7] = \"DT_STRING\", e[e.DT_COMPLEX64 = 8] = \"DT_COMPLEX64\", e[e.DT_INT64 = 9] = \"DT_INT64\", e[e.DT_BOOL = 10] = \"DT_BOOL\", e[e.DT_QINT8 = 11] = \"DT_QINT8\", e[e.DT_QUINT8 = 12] = \"DT_QUINT8\", e[e.DT_QINT32 = 13] = \"DT_QINT32\", e[e.DT_BFLOAT16 = 14] = \"DT_BFLOAT16\", e[e.DT_FLOAT_REF = 101] = \"DT_FLOAT_REF\", e[e.DT_DOUBLE_REF = 102] = \"DT_DOUBLE_REF\", e[e.DT_INT32_REF = 103] = \"DT_INT32_REF\", e[e.DT_UINT8_REF = 104] = \"DT_UINT8_REF\", e[e.DT_INT16_REF = 105] = \"DT_INT16_REF\", e[e.DT_INT8_REF = 106] = \"DT_INT8_REF\", e[e.DT_STRING_REF = 107] = \"DT_STRING_REF\", e[e.DT_COMPLEX64_REF = 108] = \"DT_COMPLEX64_REF\", e[e.DT_INT64_REF = 109] = \"DT_INT64_REF\", e[e.DT_BOOL_REF = 110] = \"DT_BOOL_REF\", e[e.DT_QINT8_REF = 111] = \"DT_QINT8_REF\", e[e.DT_QUINT8_REF = 112] = \"DT_QUINT8_REF\", e[e.DT_QINT32_REF = 113] = \"DT_QINT32_REF\", e[e.DT_BFLOAT16_REF = 114] = \"DT_BFLOAT16_REF\";\n  }(e.DataType || (e.DataType = {})), function (e) {\n    !function (e) {\n      e[e.LEGACY = 0] = \"LEGACY\", e[e.V1 = 1] = \"V1\", e[e.V2 = 2] = \"V2\";\n    }(e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}));\n  }(e.SaverDef || (e.SaverDef = {}));\n}(tensorflow_json || (tensorflow_json = {}));\n\nvar CONTROL_FLOW_OPS$1 = [\"Switch\", \"Merge\", \"Enter\", \"Exit\", \"NextIteration\"],\n    DYNAMIC_SHAPE_OPS$1 = [\"NonMaxSuppressionV2\", \"NonMaxSuppressionV3\", \"Where\"],\n    OperationMapper$1 = function () {\n  function e() {\n    var e = [arithmetic, basicMath, control, convolution, creation, dynamic, evaluation, logical, image$1, graph, matrices, normalization, reduction, sliceJoin, spectral, transformation],\n        t = [].concat.apply([], e.map(function (e) {\n      return e.json;\n    }));\n    this.opMappers = t.reduce(function (e, t) {\n      return e[t.tfOpName] = t, e;\n    }, {});\n  }\n\n  return Object.defineProperty(e, \"Instance\", {\n    get: function get() {\n      return this._instance || (this._instance = new this());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.isControlFlow = function (e) {\n    return CONTROL_FLOW_OPS$1.some(function (t) {\n      return t === e.op;\n    });\n  }, e.prototype.isDynamicShape = function (e) {\n    return DYNAMIC_SHAPE_OPS$1.some(function (t) {\n      return t === e.op;\n    });\n  }, e.prototype.transformGraph = function (e) {\n    var t = this,\n        a = !1,\n        r = !1,\n        n = [],\n        o = [],\n        s = e.node.reduce(function (e, s) {\n      return e[s.name] = t.mapNode(s), t.isControlFlow(s) && (a = !0), t.isDynamicShape(s) && (r = !0), \"Placeholder\" === s.op && n.push(e[s.name]), \"Const\" === s.op && o.push(e[s.name]), e;\n    }, {}),\n        i = [],\n        p = [];\n    return Object.keys(s).forEach(function (e) {\n      var t = s[e];\n      t.inputNames.forEach(function (e) {\n        var a = getNodeNameAndIndex(e)[0];\n        t.inputs.push(s[a]), s[a].children.push(t);\n      }), 0 === t.inputs.length && i.push(t);\n    }), Object.keys(s).forEach(function (e) {\n      var t = s[e];\n      0 === t.children.length && p.push(t);\n    }), {\n      nodes: s,\n      inputs: i,\n      outputs: p,\n      weights: o,\n      placeholders: n,\n      withControlFlow: a,\n      withDynamicShape: r\n    };\n  }, e.prototype.mapNode = function (e) {\n    var t = this,\n        a = this.opMappers[e.op];\n    if (void 0 === a) throw new Error(\"Tensorflow Op is not supported: \" + e.op);\n    var r = {\n      name: e.name,\n      op: a.dlOpName,\n      category: a.category,\n      inputNames: (e.input || []).map(function (e) {\n        return e.startsWith(\"^\") ? e.substr(1) : e;\n      }),\n      inputs: [],\n      children: [],\n      params: {}\n    };\n    return a.params && (r.params = a.params.reduce(function (a, r) {\n      var n = r.tfInputIndex,\n          o = r.tfInputParamLength,\n          s = r.type,\n          i = void 0;\n      if (void 0 === n) switch (r.type) {\n        case \"string\":\n          void 0 === (i = t.getStringParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getStringParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"number\":\n          void 0 === (i = t.getNumberParam(e.attr, r.tfParamName, r.defaultValue || 0)) && r.tfParamNameDeprecated && (i = t.getNumberParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"number[]\":\n          void 0 === (i = t.getNumericArrayParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getNumericArrayParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"bool\":\n          void 0 === (i = t.getBoolParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getBoolParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"shape\":\n          void 0 === (i = t.getTensorShapeParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getTensorShapeParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"dtype\":\n          void 0 === (i = t.getDtypeParam(e.attr, r.tfParamName, r.defaultValue)) && r.tfParamNameDeprecated && (i = t.getDtypeParam(e.attr, r.tfParamNameDeprecated, r.defaultValue));\n          break;\n\n        case \"tensor\":\n        case \"tensors\":\n          break;\n\n        default:\n          throw new Error(\"Unsupported param type: \" + r.type + \" for op: \" + e.op);\n      }\n      return a[r.dlParamName] = {\n        value: i,\n        inputIndex: n,\n        type: s,\n        inputParamLength: o\n      }, a;\n    }, {})), r;\n  }, e.prototype.decodeBase64 = function (e) {\n    if (\"undefined\" != typeof atob) return atob(e);\n    if (\"undefined\" != typeof Buffer) return new Buffer(e, \"base64\").toString();\n    throw new Error(\"Unable to decode base64 in this environment. Missing built-in atob() or Buffer()\");\n  }, e.prototype.getStringParam = function (e, t, a, r) {\n    void 0 === r && (r = !1);\n    var n = e[t];\n\n    if (void 0 !== n) {\n      var o = Array.isArray(n.s) ? String.fromCharCode.apply(null, n.s) : this.decodeBase64(n.s);\n      return r ? o : o.toLowerCase();\n    }\n\n    return a;\n  }, e.prototype.getBoolParam = function (e, t, a) {\n    var r = e[t];\n    return r ? r.b : a;\n  }, e.prototype.getNumberParam = function (e, t, a) {\n    var r = e[t] || {},\n        n = r.i ? r.i : r.f ? r.f : a;\n    return \"number\" == typeof n ? n : parseInt(n, 10);\n  }, e.prototype.getDtypeParam = function (e, t, a) {\n    var r = e[t];\n\n    if (r && r.type) {\n      var n = r.type;\n\n      switch (\"string\" == typeof r.type && (n = tensorflow_json.DataType[r.type]), n) {\n        case tensorflow_json.DataType.DT_FLOAT:\n          return \"float32\";\n\n        case tensorflow_json.DataType.DT_INT32:\n          return \"int32\";\n\n        case tensorflow_json.DataType.DT_BOOL:\n          return \"bool\";\n\n        default:\n          return a;\n      }\n    }\n\n    return a;\n  }, e.prototype.getTensorShapeParam = function (e, t, a) {\n    var r = e[t];\n\n    if (r && r.shape) {\n      if (r.shape.unknownRank) return;\n      if (null != r.shape.dim) return r.shape.dim.map(function (e) {\n        return \"number\" == typeof e.size ? e.size : parseInt(e.size, 10);\n      });\n    }\n\n    return a;\n  }, e.prototype.getNumericArrayParam = function (e, t, a) {\n    var r = e[t];\n    return r ? (r.list.f && r.list.f.length ? r.list.f : r.list.i).map(function (e) {\n      return \"number\" == typeof e ? e : parseInt(e, 10);\n    }) : a;\n  }, e;\n}(),\n    FrozenModel$1 = function () {\n  function e(e, t, a, r) {\n    this.modelUrl = e, this.requestOption = t, this.weightPrefix = a, this.onProgress = r, this.version = \"n/a\";\n  }\n\n  return Object.defineProperty(e.prototype, \"modelVersion\", {\n    get: function get() {\n      return this.version;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function get() {\n      return this.executor.inputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function get() {\n      return this.executor.outputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function get() {\n      return this.executor.inputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function get() {\n      return this.executor.outputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"weights\", {\n    get: function get() {\n      return this.executor.weightMap;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.findIOHandler = function () {\n    var e = this.modelUrl;\n    if (this.requestOption || this.weightPrefix) this.handler = io.browserHTTPRequest(e, this.requestOption, this.weightPrefix, null, this.onProgress);else {\n      var t = io.getLoadHandlers(e, this.onProgress);\n      if (0 === t.length) t.push(io.browserHTTPRequest(e, this.requestOption, this.weightPrefix, null, this.onProgress));else if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") load handlers for URL '\" + [e] + \"'\");\n      this.handler = t[0];\n    }\n  }, e.prototype.load = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var e, t, a;\n      return __generator(this, function (r) {\n        switch (r.label) {\n          case 0:\n            if (this.findIOHandler(), null == this.handler.load) throw new Error(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n            return [4, this.handler.load()];\n\n          case 1:\n            return e = r.sent(), t = e.modelTopology, this.version = t.versions.producer + \".\" + t.versions.minConsumer, a = io.decodeWeights(e.weightData, e.weightSpecs), this.executor = new GraphExecutor(OperationMapper$1.Instance.transformGraph(t)), this.executor.weightMap = this.convertTensorMapToTensorsMap(a), [2, !0];\n        }\n      });\n    });\n  }, e.prototype.predict = function (e, t) {\n    return this.execute_(e, !0, this.outputNodes);\n  }, e.prototype.constructTensorMap = function (e) {\n    var t = e instanceof Tensor ? [e] : e;\n    if (t.length !== this.inputNodes.length) throw new Error(\"Input tensor count mismatch,the frozen model has \" + this.inputNodes.length + \" placeholders, while there are \" + t.length + \" input tensors.\");\n    return this.inputNodes.reduce(function (e, a, r) {\n      return e[a] = t[r], e;\n    }, {});\n  }, e.prototype.execute = function (e, t) {\n    return this.execute_(e, !1, t);\n  }, e.prototype.execute_ = function (e, t, a) {\n    if (void 0 === t && (t = !0), a = a || this.outputNodes, (e instanceof Tensor || Array.isArray(e)) && (e = this.constructTensorMap(e)), this.executor.isControlFlowModel || this.executor.isDynamicShapeModel) throw new Error(\"The model contains control flow or dynamic shape ops, please use executeAsync method\");\n    var r = this.executor.execute(this.convertTensorMapToTensorsMap(e), t, a),\n        n = Object.keys(r);\n    return Array.isArray(a) && a.length > 1 ? a.map(function (e) {\n      return r[e];\n    }) : r[n[0]];\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a, r;\n      return __generator(this, function (n) {\n        switch (n.label) {\n          case 0:\n            if (!this.executor.isControlFlowModel && !this.executor.isDynamicShapeModel) throw new Error(\"The model does not contain control flow or dynamic shape ops, please use execute method for better performance.\");\n            return t = t || this.outputNodes, (e instanceof Tensor || Array.isArray(e)) && (e = this.constructTensorMap(e)), [4, this.executor.executeAsync(this.convertTensorMapToTensorsMap(e), t)];\n\n          case 1:\n            return a = n.sent(), r = Object.keys(a), [2, Array.isArray(t) && t.length > 1 ? t.map(function (e) {\n              return a[e];\n            }) : a[r[0]]];\n        }\n      });\n    });\n  }, e.prototype.convertTensorMapToTensorsMap = function (e) {\n    return Object.keys(e).reduce(function (t, a) {\n      return t[a] = [e[a]], t;\n    }, {});\n  }, e.prototype.dispose = function () {\n    this.executor.dispose();\n  }, e;\n}();\n\nfunction loadFrozenModel$1(e, t, a) {\n  return __awaiter(this, void 0, void 0, function () {\n    var r;\n    return __generator(this, function (n) {\n      switch (n.label) {\n        case 0:\n          return [4, (r = new FrozenModel$1(e, t, null, a)).load()];\n\n        case 1:\n          return n.sent(), [2, r];\n      }\n    });\n  });\n}\n\nvar version = \"0.8.4\";\n\nfunction loadFrozenModel$2(e, t, a, r) {\n  return deprecationWarn(\"tf.loadFrozenModel() is going away. Use tf.loadGraphModel() instead, and note the positional argument changes.\"), e && e.endsWith(\".json\") ? loadFrozenModel$1(e, a, r) : (null != e && null == t && (t = getWeightsManifestUrl(e)), loadFrozenModel(e, t, a, r));\n}\n\nfunction getWeightsManifestUrl(e) {\n  var t;\n  null != e && (t = e.substr(0, e.lastIndexOf(\"/\")) + \"/\" + DEFAULT_MANIFEST_NAME);\n  return t;\n}\n\nfunction loadGraphModel(e, t) {\n  if (void 0 === t && (t = {}), null == t && (t = {}), t.fromTFHub) return loadTfHubModule(e, t.requestInit, t.onProgress);\n  var a = void 0;\n  return e && e.endsWith(\".json\") ? loadFrozenModel$1(e, t.requestInit, t.onProgress) : (null != e && null == a && (a = getWeightsManifestUrl(e)), loadFrozenModel(e, a, t.requestInit, t.onProgress));\n}\n\nexport { loadFrozenModel$2 as loadFrozenModel, loadGraphModel, FrozenModel, loadTfHubModule, FrozenModel as GraphModel, FrozenModel$1 as FrozenModelJSON, version as version_converter };","map":null,"metadata":{},"sourceType":"module"}