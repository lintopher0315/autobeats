{"ast":null,"code":"\"use strict\";\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [op[0] & 2, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tf = require(\"@tensorflow/tfjs\");\n\nvar aux_inputs = require(\"../core/aux_inputs\");\n\nvar chords = require(\"../core/chords\");\n\nvar data = require(\"../core/data\");\n\nvar logging = require(\"../core/logging\");\n\nvar sequences = require(\"../core/sequences\");\n\nvar attention_1 = require(\"./attention\");\n\nvar CELL_FORMAT = 'multi_rnn_cell/cell_%d/basic_lstm_cell/';\n\nvar MusicRNN = function () {\n  function MusicRNN(checkpointURL, spec) {\n    this.checkpointURL = checkpointURL;\n    this.spec = spec;\n    this.initialized = false;\n    this.rawVars = {};\n    this.biasShapes = [];\n    this.lstmCells = [];\n  }\n\n  MusicRNN.prototype.isInitialized = function () {\n    return this.initialized;\n  };\n\n  MusicRNN.prototype.instantiateFromSpec = function () {\n    this.dataConverter = data.converterFromSpec(this.spec.dataConverter);\n    this.attentionLength = this.spec.attentionLength;\n    this.chordEncoder = this.spec.chordEncoder ? chords.chordEncoderFromType(this.spec.chordEncoder) : undefined;\n    this.auxInputs = this.spec.auxInputs ? this.spec.auxInputs.map(function (s) {\n      return aux_inputs.auxiliaryInputFromSpec(s);\n    }) : undefined;\n  };\n\n  MusicRNN.prototype.initialize = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var startTime, vars, hasAttention, rnnPrefix, l, _loop_1, this_1, state_1;\n\n      var _this = this;\n\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            this.dispose();\n            startTime = performance.now();\n            if (!!this.spec) return [3, 2];\n            return [4, fetch(this.checkpointURL + \"/config.json\").then(function (response) {\n              return response.json();\n            }).then(function (spec) {\n              if (spec.type !== 'MusicRNN') {\n                throw new Error(\"Attempted to instantiate MusicRNN model with incorrect type:\\n                  \" + spec.type);\n              }\n\n              _this.spec = spec;\n            })];\n\n          case 1:\n            _a.sent();\n\n            _a.label = 2;\n\n          case 2:\n            this.instantiateFromSpec();\n            return [4, fetch(this.checkpointURL + \"/weights_manifest.json\").then(function (response) {\n              return response.json();\n            }).then(function (manifest) {\n              return tf.io.loadWeights(manifest, _this.checkpointURL);\n            })];\n\n          case 3:\n            vars = _a.sent();\n            hasAttention = attention_1.AttentionWrapper.isWrapped(vars);\n            rnnPrefix = hasAttention ? \"rnn/\" + attention_1.ATTENTION_PREFIX : 'rnn/';\n            this.forgetBias = tf.scalar(1.0);\n            this.lstmCells.length = 0;\n            this.biasShapes.length = 0;\n            l = 0;\n\n            _loop_1 = function _loop_1() {\n              var cellPrefix = rnnPrefix + CELL_FORMAT.replace('%d', l.toString());\n\n              if (!(cellPrefix + \"kernel\" in vars)) {\n                return \"break\";\n              }\n\n              this_1.lstmCells.push(function (data, c, h) {\n                return tf.basicLSTMCell(_this.forgetBias, vars[cellPrefix + \"kernel\"], vars[cellPrefix + \"bias\"], data, c, h);\n              });\n              this_1.biasShapes.push(vars[cellPrefix + \"bias\"].shape[0]);\n              ++l;\n            };\n\n            this_1 = this;\n\n            while (true) {\n              state_1 = _loop_1();\n              if (state_1 === \"break\") break;\n            }\n\n            this.lstmFcW = vars['fully_connected/weights'];\n            this.lstmFcB = vars['fully_connected/biases'];\n\n            if (hasAttention) {\n              this.attentionWrapper = new attention_1.AttentionWrapper(this.lstmCells, this.attentionLength, this.biasShapes[0] / 4);\n              this.attentionWrapper.initialize(vars);\n            }\n\n            this.rawVars = vars;\n            this.initialized = true;\n            logging.logWithDuration('Initialized model', startTime, 'MusicRNN');\n            return [2];\n        }\n      });\n    });\n  };\n\n  MusicRNN.prototype.dispose = function () {\n    var _this = this;\n\n    Object.keys(this.rawVars).forEach(function (name) {\n      return _this.rawVars[name].dispose();\n    });\n    this.rawVars = {};\n\n    if (this.forgetBias) {\n      this.forgetBias.dispose();\n      this.forgetBias = undefined;\n    }\n\n    this.initialized = false;\n  };\n\n  MusicRNN.prototype.continueSequence = function (sequence, steps, temperature, chordProgression) {\n    return __awaiter(this, void 0, void 0, function () {\n      var result;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            return [4, this.continueSequenceImpl(sequence, steps, temperature, chordProgression, false)];\n\n          case 1:\n            result = _a.sent();\n            return [2, result.sequence];\n        }\n      });\n    });\n  };\n\n  MusicRNN.prototype.continueSequenceAndReturnProbabilities = function (sequence, steps, temperature, chordProgression) {\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (_a) {\n        return [2, this.continueSequenceImpl(sequence, steps, temperature, chordProgression, true)];\n      });\n    });\n  };\n\n  MusicRNN.prototype.continueSequenceImpl = function (sequence, steps, temperature, chordProgression, returnProbs) {\n    return __awaiter(this, void 0, void 0, function () {\n      var startTime, oh, samplesAndProbs, result, probs, i, _a, _b;\n\n      var _this = this;\n\n      return __generator(this, function (_c) {\n        switch (_c.label) {\n          case 0:\n            sequences.assertIsRelativeQuantizedSequence(sequence);\n\n            if (this.chordEncoder && !chordProgression) {\n              throw new Error('Chord progression expected but not provided.');\n            }\n\n            if (!this.chordEncoder && chordProgression) {\n              throw new Error('Unexpected chord progression provided.');\n            }\n\n            if (!!this.initialized) return [3, 2];\n            return [4, this.initialize()];\n\n          case 1:\n            _c.sent();\n\n            _c.label = 2;\n\n          case 2:\n            startTime = performance.now();\n            oh = tf.tidy(function () {\n              var inputs = _this.dataConverter.toTensor(sequence);\n\n              var length = inputs.shape[0];\n              var outputSize = inputs.shape[1];\n              var controls = _this.chordEncoder ? _this.chordEncoder.encodeProgression(chordProgression, length + steps) : undefined;\n              var auxInputs = _this.auxInputs ? tf.concat(_this.auxInputs.map(function (auxInput) {\n                return auxInput.getTensors(length + steps);\n              }), 1) : undefined;\n\n              var rnnResult = _this.sampleRnn(inputs, steps, temperature, controls, auxInputs, returnProbs);\n\n              var samples = rnnResult.samples;\n              return {\n                samples: tf.stack(samples).as2D(samples.length, outputSize),\n                probs: rnnResult.probs\n              };\n            });\n            return [4, oh];\n\n          case 3:\n            samplesAndProbs = _c.sent();\n            result = this.dataConverter.toNoteSequence(samplesAndProbs.samples, sequence.quantizationInfo.stepsPerQuarter);\n            probs = [];\n            if (!returnProbs) return [3, 7];\n            i = 0;\n            _c.label = 4;\n\n          case 4:\n            if (!(i < samplesAndProbs.probs.length)) return [3, 7];\n            _b = (_a = probs).push;\n            return [4, samplesAndProbs.probs[i].data()];\n\n          case 5:\n            _b.apply(_a, [_c.sent()]);\n\n            samplesAndProbs.probs[i].dispose();\n            _c.label = 6;\n\n          case 6:\n            i++;\n            return [3, 4];\n\n          case 7:\n            oh.samples.dispose();\n            result.then(function () {\n              return logging.logWithDuration('Continuation completed', startTime, 'MusicRNN', 20);\n            });\n            return [2, {\n              sequence: result,\n              probs: probs\n            }];\n        }\n      });\n    });\n  };\n\n  MusicRNN.prototype.sampleRnn = function (inputs, steps, temperature, controls, auxInputs, returnProbs) {\n    var _a;\n\n    var length = inputs.shape[0];\n    var outputSize = inputs.shape[1];\n    var c = [];\n    var h = [];\n\n    for (var i = 0; i < this.biasShapes.length; i++) {\n      c.push(tf.zeros([1, this.biasShapes[i] / 4]));\n      h.push(tf.zeros([1, this.biasShapes[i] / 4]));\n    }\n\n    var attentionState = this.attentionWrapper ? this.attentionWrapper.initState() : null;\n    var lastOutput;\n    inputs = inputs.toFloat();\n    var samples = [];\n    var probs = [];\n    var splitInputs = tf.split(inputs.toFloat(), length);\n    var splitControls = controls ? tf.split(controls, controls.shape[0]) : undefined;\n    var splitAuxInputs = auxInputs ? tf.split(auxInputs, auxInputs.shape[0]) : undefined;\n\n    for (var i = 0; i < length + steps; i++) {\n      var nextInput = void 0;\n\n      if (i < length) {\n        nextInput = splitInputs[i];\n      } else {\n        var logits = lastOutput.matMul(this.lstmFcW).add(this.lstmFcB).as1D();\n        var sampledOutput = void 0;\n\n        if (temperature) {\n          logits = logits.div(tf.scalar(temperature));\n          sampledOutput = tf.multinomial(logits, 1).as1D();\n        } else {\n          sampledOutput = logits.argMax().as1D();\n        }\n\n        if (returnProbs) {\n          probs.push(tf.softmax(logits));\n        }\n\n        nextInput = tf.oneHot(sampledOutput, outputSize).toFloat();\n        samples.push(nextInput.as1D());\n      }\n\n      if (i === length + steps - 1) {\n        break;\n      }\n\n      var tensors = [];\n\n      if (splitControls) {\n        tensors.push(splitControls[i + 1]);\n      }\n\n      tensors.push(nextInput);\n\n      if (splitAuxInputs) {\n        tensors.push(splitAuxInputs[i]);\n      }\n\n      nextInput = tf.concat(tensors, 1);\n\n      if (this.attentionWrapper) {\n        var wrapperOutput = this.attentionWrapper.call(nextInput, c, h, attentionState);\n        c = wrapperOutput.c;\n        h = wrapperOutput.h;\n        attentionState = wrapperOutput.attentionState;\n        lastOutput = wrapperOutput.output;\n      } else {\n        _a = tf.multiRNNCell(this.lstmCells, nextInput, c, h), c = _a[0], h = _a[1];\n        lastOutput = h[h.length - 1];\n      }\n    }\n\n    return {\n      samples: samples,\n      probs: probs\n    };\n  };\n\n  return MusicRNN;\n}();\n\nexports.MusicRNN = MusicRNN;","map":null,"metadata":{},"sourceType":"script"}