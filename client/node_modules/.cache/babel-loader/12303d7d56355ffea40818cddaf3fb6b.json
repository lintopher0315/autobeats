{"ast":null,"code":"\"use strict\";\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [op[0] & 2, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tf = require(\"@tensorflow/tfjs\");\n\nvar audio_utils_1 = require(\"../core/audio_utils\");\n\nvar logging = require(\"../core/logging\");\n\nvar audio_utils_2 = require(\"./audio_utils\");\n\nvar constants_1 = require(\"./constants\");\n\nvar transcription_utils_1 = require(\"./transcription_utils\");\n\nvar OnsetsAndFrames = function () {\n  function OnsetsAndFrames(checkpointURL, chunkLength) {\n    if (chunkLength === void 0) {\n      chunkLength = 250;\n    }\n\n    this.checkpointURL = checkpointURL;\n    this.chunkLength = chunkLength;\n  }\n\n  OnsetsAndFrames.prototype.initialize = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var startTime, vars;\n\n      var _this = this;\n\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            this.dispose();\n            startTime = performance.now();\n            return [4, fetch(this.checkpointURL + \"/weights_manifest.json\").then(function (response) {\n              return response.json();\n            }).then(function (manifest) {\n              return tf.io.loadWeights(manifest, _this.checkpointURL);\n            })];\n\n          case 1:\n            vars = _a.sent();\n            this.build(vars);\n            Object.keys(vars).map(function (name) {\n              return vars[name].dispose();\n            });\n            this.initialized = true;\n            logging.logWithDuration('Initialized model', startTime, 'O&F');\n            return [2];\n        }\n      });\n    });\n  };\n\n  OnsetsAndFrames.prototype.dispose = function () {\n    if (!this.initialized) {\n      return;\n    }\n\n    this.onsetsCnn.dispose();\n    this.onsetsRnn.dispose();\n    this.activationCnn.dispose();\n    this.frameRnn.dispose();\n    this.velocityCnn.dispose();\n    this.initialized = false;\n  };\n\n  OnsetsAndFrames.prototype.isInitialized = function () {\n    return this.initialized;\n  };\n\n  OnsetsAndFrames.prototype.transcribeFromMelSpec = function (melSpec, parallelBatches) {\n    if (parallelBatches === void 0) {\n      parallelBatches = 4;\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var startTime, _a, frameProbs, onsetProbs, velocities, ns;\n\n      var _this = this;\n\n      return __generator(this, function (_b) {\n        if (!this.isInitialized()) {\n          this.initialize();\n        }\n\n        startTime = performance.now();\n        logging.log('Computing onsets, frames, and velocities...', 'O&F', 20);\n        _a = tf.tidy(function () {\n          var batches = transcription_utils_1.batchInput(melSpec, _this.chunkLength);\n          return _this.processBatches(batches, _this.chunkLength, melSpec.length, parallelBatches);\n        }), frameProbs = _a[0], onsetProbs = _a[1], velocities = _a[2];\n        logging.log('Converting to NoteSequence...', 'O&F', 20);\n        ns = transcription_utils_1.pianorollToNoteSequence(frameProbs, onsetProbs, velocities);\n        ns.then(function () {\n          frameProbs.dispose();\n          onsetProbs.dispose();\n          velocities.dispose();\n          logging.logWithDuration('Transcribed from mel spec', startTime, 'O&F');\n        });\n        return [2, ns];\n      });\n    });\n  };\n\n  OnsetsAndFrames.prototype.transcribeFromAudioBuffer = function (audioBuffer, batchSize) {\n    if (batchSize === void 0) {\n      batchSize = 4;\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var startTime, melSpec;\n\n      var _this = this;\n\n      return __generator(this, function (_a) {\n        startTime = performance.now();\n        melSpec = audio_utils_2.preprocessAudio(audioBuffer);\n        melSpec.then(function () {\n          return logging.logWithDuration('Converted audio to mel spec', startTime, 'O&F', 20);\n        });\n        return [2, melSpec.then(function (spec) {\n          return _this.transcribeFromMelSpec(spec.map(function (a) {\n            return Array.from(a);\n          }, batchSize));\n        })];\n      });\n    });\n  };\n\n  OnsetsAndFrames.prototype.transcribeFromAudioFile = function (blob) {\n    return __awaiter(this, void 0, void 0, function () {\n      var audio;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            return [4, audio_utils_1.loadAudioFromFile(blob)];\n\n          case 1:\n            audio = _a.sent();\n            return [2, this.transcribeFromAudioBuffer(audio)];\n        }\n      });\n    });\n  };\n\n  OnsetsAndFrames.prototype.transcribeFromAudioURL = function (url) {\n    return __awaiter(this, void 0, void 0, function () {\n      var audio;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            return [4, audio_utils_1.loadAudioFromUrl(url)];\n\n          case 1:\n            audio = _a.sent();\n            return [2, this.transcribeFromAudioBuffer(audio)];\n        }\n      });\n    });\n  };\n\n  OnsetsAndFrames.prototype.processBatches = function (batches, chunkLength, fullLength, batchSize) {\n    var _this = this;\n\n    var _a;\n\n    var runCnns = function runCnns(batch) {\n      return [_this.onsetsCnn.predict(batch, batchSize), _this.activationCnn.predict(batch, batchSize), _this.velocityCnn.predict(batch, batchSize)];\n    };\n\n    var onsetsCnnOut, activationProbs, scaledVelocities;\n\n    if (batches.shape[0] === 1) {\n      _a = runCnns(batches.expandDims(-1)), onsetsCnnOut = _a[0], activationProbs = _a[1], scaledVelocities = _a[2];\n    } else {\n      var batchesOutput = runCnns(batches.expandDims(-1));\n      var allOutputs = [];\n\n      for (var i = 0; i < 3; ++i) {\n        allOutputs.push(transcription_utils_1.unbatchOutput(batchesOutput[i], chunkLength, fullLength));\n      }\n\n      onsetsCnnOut = allOutputs[0], activationProbs = allOutputs[1], scaledVelocities = allOutputs[2];\n    }\n\n    var onsetProbs = this.onsetsRnn.predict(onsetsCnnOut, this.chunkLength);\n    onsetsCnnOut.dispose();\n    var frameProbInputs = tf.concat3d([onsetProbs, activationProbs], -1);\n    activationProbs.dispose();\n    var frameProbs = this.frameRnn.predict(frameProbInputs, this.chunkLength);\n    var velocities = tf.clipByValue(scaledVelocities, 0., 1.).mul(tf.scalar(80.)).add(tf.scalar(10.)).toInt();\n    scaledVelocities.dispose();\n    return [frameProbs.squeeze(), onsetProbs.squeeze(), velocities.squeeze()];\n  };\n\n  OnsetsAndFrames.prototype.build = function (vars) {\n    var _this = this;\n\n    tf.tidy(function () {\n      _this.onsetsCnn = new AcousticCnn();\n\n      _this.onsetsCnn.setWeights(vars, 'onsets');\n\n      _this.onsetsRnn = new Lstm([null, _this.onsetsCnn.outputShape[2]]);\n\n      _this.onsetsRnn.setWeights(vars, 'onsets', 'onset_probs');\n\n      _this.activationCnn = new AcousticCnn('sigmoid');\n\n      _this.activationCnn.setWeights(vars, 'frame', 'activation_probs');\n\n      _this.frameRnn = new Lstm([null, constants_1.MIDI_PITCHES * 2]);\n\n      _this.frameRnn.setWeights(vars, 'frame', 'frame_probs');\n\n      _this.velocityCnn = new AcousticCnn('linear');\n\n      _this.velocityCnn.setWeights(vars, 'velocity', 'onset_velocities');\n    });\n  };\n\n  return OnsetsAndFrames;\n}();\n\nexports.OnsetsAndFrames = OnsetsAndFrames;\n\nvar AcousticCnn = function () {\n  function AcousticCnn(finalDenseActivation) {\n    this.nn = tf.sequential();\n    var convConfig = {\n      filters: 48,\n      kernelSize: [3, 3],\n      activation: 'linear',\n      useBias: false,\n      padding: 'same',\n      dilationRate: [1, 1],\n      inputShape: [null, constants_1.MEL_SPEC_BINS, 1],\n      trainable: false\n    };\n    var batchNormConfig = {\n      scale: false,\n      trainable: false\n    };\n    this.nn.add(tf.layers.conv2d(convConfig));\n    this.nn.add(tf.layers.batchNormalization(batchNormConfig));\n    this.nn.add(tf.layers.activation({\n      activation: 'relu'\n    }));\n    convConfig.inputShape = null;\n    this.nn.add(tf.layers.conv2d(convConfig));\n    this.nn.add(tf.layers.batchNormalization(batchNormConfig));\n    this.nn.add(tf.layers.activation({\n      activation: 'relu'\n    }));\n    this.nn.add(tf.layers.maxPooling2d({\n      poolSize: [1, 2],\n      strides: [1, 2]\n    }));\n    convConfig.filters = 96;\n    this.nn.add(tf.layers.conv2d(convConfig));\n    this.nn.add(tf.layers.batchNormalization(batchNormConfig));\n    this.nn.add(tf.layers.activation({\n      activation: 'relu'\n    }));\n    this.nn.add(tf.layers.maxPooling2d({\n      poolSize: [1, 2],\n      strides: [1, 2]\n    }));\n    var dims = this.nn.outputShape;\n    this.nn.add(tf.layers.reshape({\n      targetShape: [dims[1], dims[2] * dims[3]]\n    }));\n    this.nn.add(tf.layers.dense({\n      units: 768,\n      activation: 'relu',\n      trainable: false\n    }));\n\n    if (finalDenseActivation) {\n      this.nn.add(tf.layers.dense({\n        units: constants_1.MIDI_PITCHES,\n        activation: finalDenseActivation,\n        trainable: false\n      }));\n    }\n\n    this.outputShape = this.nn.outputShape;\n  }\n\n  AcousticCnn.prototype.dispose = function () {\n    this.nn.dispose();\n  };\n\n  AcousticCnn.prototype.predict = function (inputs, batchSize) {\n    return this.nn.predict(inputs, {\n      batchSize: batchSize\n    });\n  };\n\n  AcousticCnn.prototype.setWeights = function (vars, scope, denseName) {\n    function getVar(name) {\n      var v = vars[name];\n\n      if (v === undefined) {\n        throw Error(\"Variable not found: \" + name);\n      }\n\n      return v;\n    }\n\n    var weights = [getVar(scope + \"/conv0/weights\"), getVar(scope + \"/conv0/BatchNorm/beta\"), getVar(scope + \"/conv0/BatchNorm/moving_mean\"), getVar(scope + \"/conv0/BatchNorm/moving_variance\"), getVar(scope + \"/conv1/weights\"), getVar(scope + \"/conv1/BatchNorm/beta\"), getVar(scope + \"/conv1/BatchNorm/moving_mean\"), getVar(scope + \"/conv1/BatchNorm/moving_variance\"), getVar(scope + \"/conv2/weights\"), getVar(scope + \"/conv2/BatchNorm/beta\"), getVar(scope + \"/conv2/BatchNorm/moving_mean\"), getVar(scope + \"/conv2/BatchNorm/moving_variance\"), getVar(scope + \"/fc_end/weights\"), getVar(scope + \"/fc_end/biases\")];\n\n    if (denseName) {\n      weights = weights.concat([getVar(scope + \"/\" + denseName + \"/weights\"), getVar(scope + \"/\" + denseName + \"/biases\")]);\n    }\n\n    this.nn.setWeights(weights);\n  };\n\n  return AcousticCnn;\n}();\n\nvar Lstm = function () {\n  function Lstm(inputShape, units) {\n    if (units === void 0) {\n      units = 384;\n    }\n\n    this.dense = tf.sequential();\n    this.units = units;\n\n    function getLstm() {\n      var lstm = tf.layers.lstm({\n        inputShape: inputShape,\n        units: units,\n        returnSequences: true,\n        recurrentActivation: 'sigmoid',\n        returnState: true,\n        kernelInitializer: 'zeros',\n        recurrentInitializer: 'zeros',\n        biasInitializer: 'zeros',\n        trainable: false\n      });\n      var inputs = [tf.input({\n        shape: inputShape\n      }), tf.input({\n        shape: [units]\n      }), tf.input({\n        shape: [units]\n      })];\n      var outputs = lstm.apply(inputs);\n      return tf.model({\n        inputs: inputs,\n        outputs: outputs\n      });\n    }\n\n    this.lstm = getLstm();\n    this.dense.add(tf.layers.dense({\n      inputShape: [null, units],\n      units: constants_1.MIDI_PITCHES,\n      activation: 'sigmoid',\n      trainable: false\n    }));\n  }\n\n  Lstm.prototype.dispose = function () {\n    this.lstm.dispose();\n    this.dense.dispose();\n  };\n\n  Lstm.prototype.setWeights = function (vars, scope, denseName) {\n    var _this = this;\n\n    function getVar(name) {\n      var v = vars[name];\n\n      if (v === undefined) {\n        throw Error(\"Variable not found: \" + name);\n      }\n\n      return v;\n    }\n\n    var reorderGates = function reorderGates(weights, forgetBias) {\n      if (forgetBias === void 0) {\n        forgetBias = 0;\n      }\n\n      var _a = tf.split(weights, 4, -1),\n          i = _a[0],\n          c = _a[1],\n          f = _a[2],\n          o = _a[3];\n\n      return tf.concat([i, f.add(tf.scalar(forgetBias)), c, o], -1);\n    };\n\n    var splitAndReorderKernel = function splitAndReorderKernel(kernel) {\n      return tf.split(reorderGates(kernel), [kernel.shape[0] - _this.units, _this.units]);\n    };\n\n    var LSTM_PREFIX = 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell';\n\n    var setLstmWeights = function setLstmWeights(lstm) {\n      return lstm.setWeights(splitAndReorderKernel(getVar(scope + \"/\" + LSTM_PREFIX + \"/kernel\")).concat(reorderGates(getVar(scope + \"/\" + LSTM_PREFIX + \"/bias\"), 1.0)));\n    };\n\n    setLstmWeights(this.lstm);\n    this.dense.setWeights([getVar(scope + \"/\" + denseName + \"/weights\"), getVar(scope + \"/\" + denseName + \"/biases\")]);\n  };\n\n  Lstm.prototype.predict = function (inputs, chunkSize) {\n    var _this = this;\n\n    return tf.tidy(function () {\n      return _this.predictImpl(inputs, chunkSize);\n    });\n  };\n\n  Lstm.prototype.predictImpl = function (inputs, chunkSize) {\n    var fullLength = inputs.shape[1];\n    var numChunks = Math.ceil(fullLength / chunkSize);\n    var state = [tf.zeros([1, this.units]), tf.zeros([1, this.units])];\n    var outputChunks = [];\n\n    for (var i = 0; i < numChunks; ++i) {\n      var chunk = inputs.slice([0, i * chunkSize], [-1, i < numChunks - 1 ? chunkSize : -1]);\n      var result = this.lstm.predict([chunk, state[0], state[1]]);\n      outputChunks.push(this.dense.predict(result[0]));\n      state = result.slice(1);\n    }\n\n    return outputChunks.length === 1 ? outputChunks[0] : tf.concat3d(outputChunks, 1);\n  };\n\n  return Lstm;\n}();","map":null,"metadata":{},"sourceType":"script"}